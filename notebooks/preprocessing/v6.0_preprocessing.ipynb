{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b58672-6de3-4210-9468-fe5e6944d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# train_preprocess_v3.py\n",
    "# - raw ‚Üí clean ‚Üí monthly (ÏôÑÏ†Ñ Ìå®ÎÑê + Ïù¥Î≤§Ìä∏ Í∏∞Î∞ò ÌååÏÉù Ìè¨Ìï®)\n",
    "# - pairwise EDA & FE Îã®Í≥ÑÍπåÏßÄ ÏùºÍ¥ÄÎêòÍ≤å ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎäî Î≤ÑÏ†Ñ\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6111b0e2-bc6b-4db2-bc59-16ef2975dc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ RAW_PATH: /data/ephemeral/home/data/raw/train.csv\n",
      "üìå Loaded: (10836, 9)\n",
      "üì¶ monthly raw shape: (3776, 13)\n",
      "üìå monthly FULL shape: (4300, 17)\n",
      "üìå pivot_value shape: (100, 43)\n",
      "üéâ Saved:\n",
      " - /data/ephemeral/home/data/interim/train_clean_v3.csv\n",
      " - /data/ephemeral/home/data/processed/train_monthly_v3_eda.csv\n",
      " - /data/ephemeral/home/data/processed/pivot_value_v3_eda.csv\n",
      " - /data/ephemeral/home/data/processed/item_summary_v3_eda.csv\n",
      "üî• preprocess_v3_eda ÏôÑÏÑ±!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Path ÏÑ§Ï†ï\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parents[1] / \"data\"\n",
    "\n",
    "RAW_PATH        = DATA_DIR / \"raw\" / \"train.csv\"\n",
    "CLEAN_PATH      = DATA_DIR / \"interim\" / \"train_clean_v3.csv\"\n",
    "MONTHLY_PATH    = DATA_DIR / \"processed\" / \"train_monthly_v3_eda.csv\"\n",
    "PIVOT_VALUE_PATH = DATA_DIR / \"processed\" / \"pivot_value_v3_eda.csv\"\n",
    "ITEM_SUMMARY_PATH = DATA_DIR / \"processed\" / \"item_summary_v3_eda.csv\"\n",
    "\n",
    "print(\"üìÇ RAW_PATH:\", RAW_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# 1. RAW load & Í∏∞Î≥∏ ÌÉÄÏûÖ Ï†ïÎ¶¨\n",
    "# ============================================================\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "df[\"year\"]  = df[\"year\"].astype(int)\n",
    "df[\"month\"] = df[\"month\"].astype(int)\n",
    "df[\"seq\"]   = df[\"seq\"].astype(int)\n",
    "df[\"type\"]  = df[\"type\"].astype(str)\n",
    "df[\"hs4\"]   = df[\"hs4\"].astype(str).str.zfill(4)\n",
    "\n",
    "for col in [\"weight\", \"quantity\", \"value\"]:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# NA ‚Üí 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Ï§ëÎ≥µ Ï†úÍ±∞\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"üìå Loaded:\", df.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 2. HS Í≥ÑÏ∏µ ÌååÏÉù + ÎÖºÎ¶¨ Î∂àÏùºÏπò ÌîåÎûòÍ∑∏\n",
    "# ============================================================\n",
    "df[\"hs2\"] = df[\"hs4\"].str[:2]\n",
    "df[\"hs3\"] = df[\"hs4\"].str[:3]\n",
    "\n",
    "df[\"flag_v0_wpos\"] = ((df[\"value\"] == 0) & (df[\"weight\"] > 0)).astype(int)\n",
    "df[\"flag_w0_vpos\"] = ((df[\"weight\"] == 0) & (df[\"value\"] > 0)).astype(int)\n",
    "\n",
    "# ym (Ïõî Îã®ÏúÑ datetime) ÏÉùÏÑ±\n",
    "df[\"ym\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-\" +\n",
    "                          df[\"month\"].astype(str) + \"-01\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ÏõîÎ≥Ñ ÏßëÍ≥Ñ (item √ó year √ó month)\n",
    "# ============================================================\n",
    "group_cols = [\"item_id\", \"type\", \"hs4\", \"hs3\", \"hs2\", \"year\", \"month\", \"ym\"]\n",
    "\n",
    "monthly = (\n",
    "    df.groupby(group_cols, as_index=False)\n",
    "      .agg(\n",
    "          total_value=(\"value\", \"sum\"),\n",
    "          total_weight=(\"weight\", \"sum\"),\n",
    "          total_quantity=(\"quantity\", \"sum\"),\n",
    "          flag_v0_wpos=(\"flag_v0_wpos\", \"max\"),\n",
    "          flag_w0_vpos=(\"flag_w0_vpos\", \"max\"),\n",
    "      )\n",
    "      .sort_values(group_cols)\n",
    ")\n",
    "\n",
    "print(\"üì¶ monthly raw shape:\", monthly.shape)\n",
    "\n",
    "# Î°úÍ∑∏/ÎπÑÏú® ÌååÏÉù\n",
    "monthly[\"log_value\"]    = np.log1p(monthly[\"total_value\"])\n",
    "monthly[\"log_weight\"]   = np.log1p(monthly[\"total_weight\"])\n",
    "monthly[\"log_quantity\"] = np.log1p(monthly[\"total_quantity\"])\n",
    "monthly[\"wv_ratio\"]     = monthly[\"total_weight\"] / np.maximum(monthly[\"total_value\"], 1.0)\n",
    "\n",
    "# ============================================================\n",
    "# 4. ÏôÑÏ†Ñ Ìå®ÎÑê ÌôïÏû• (item √ó Î™®Îì† ym)\n",
    "# ============================================================\n",
    "items = monthly[\"item_id\"].unique()\n",
    "all_ym = pd.date_range(\n",
    "    start=monthly[\"ym\"].min(),\n",
    "    end=monthly[\"ym\"].max(),\n",
    "    freq=\"MS\",  # month start\n",
    ")\n",
    "\n",
    "full_index = pd.MultiIndex.from_product(\n",
    "    [items, all_ym],\n",
    "    names=[\"item_id\", \"ym\"],\n",
    ")\n",
    "\n",
    "monthly_full = (\n",
    "    monthly.set_index([\"item_id\", \"ym\"])\n",
    "           .reindex(full_index)\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "# year / month Î≥µÏõê\n",
    "monthly_full[\"year\"] = monthly_full[\"ym\"].dt.year\n",
    "monthly_full[\"month\"] = monthly_full[\"ym\"].dt.month\n",
    "\n",
    "# 0 fill for ÏàòÏπòÌòï\n",
    "for col in [\n",
    "    \"total_value\", \"total_weight\", \"total_quantity\",\n",
    "    \"log_value\", \"log_weight\", \"log_quantity\",\n",
    "    \"wv_ratio\", \"flag_v0_wpos\", \"flag_w0_vpos\"\n",
    "]:\n",
    "    monthly_full[col] = monthly_full[col].fillna(0)\n",
    "\n",
    "# hs/type Ï†ïÎ≥¥Îäî forward/backward fill (ÏïÑÏù¥ÌÖúÎ≥Ñ Í≥†Ï†ï)\n",
    "monthly_full = monthly_full.sort_values([\"item_id\", \"ym\"])\n",
    "monthly_full[[\"hs2\", \"hs3\", \"hs4\", \"type\"]] = (\n",
    "    monthly_full.groupby(\"item_id\")[[\"hs2\", \"hs3\", \"hs4\", \"type\"]]\n",
    "                .ffill()\n",
    "                .bfill()\n",
    ")\n",
    "\n",
    "print(\"üìå monthly FULL shape:\", monthly_full.shape)\n",
    "\n",
    "# t Ïù∏Îç±Ïä§ (EDA/Î™®Îç∏Ïö© time index)\n",
    "monthly_full = monthly_full.sort_values([\"ym\"])\n",
    "t_map = {ym: i for i, ym in enumerate(sorted(monthly_full[\"ym\"].unique()))}\n",
    "monthly_full[\"t\"] = monthly_full[\"ym\"].map(t_map)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Ïù¥Î≤§Ìä∏ ÌîåÎûòÍ∑∏\n",
    "# ============================================================\n",
    "monthly_full[\"event\"] = (monthly_full[\"total_value\"] > 0).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# 6. item-level rolling / diff / sign / lag\n",
    "# ============================================================\n",
    "def add_group_rolling(df, group_col, target_col, win_list, prefix):\n",
    "    for w in win_list:\n",
    "        col_name_mean = f\"{prefix}_mean_{w}\"\n",
    "        col_name_std  = f\"{prefix}_std_{w}\"\n",
    "        df[col_name_mean] = (\n",
    "            df.groupby(group_col)[target_col]\n",
    "              .transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "        df[col_name_std] = (\n",
    "            df.groupby(group_col)[target_col]\n",
    "              .transform(lambda x: x.rolling(w, min_periods=1).std())\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# rolling 3, 6 (12Îäî Í≥ºÍ∞êÌûà Ï†úÏô∏)\n",
    "monthly_full = add_group_rolling(\n",
    "    monthly_full, group_col=\"item_id\",\n",
    "    target_col=\"total_value\",\n",
    "    win_list=[3, 6],\n",
    "    prefix=\"value_roll\"\n",
    ")\n",
    "\n",
    "# diff\n",
    "monthly_full[\"diff_value\"] = (\n",
    "    monthly_full.groupby(\"item_id\")[\"total_value\"].diff()\n",
    ")\n",
    "monthly_full[\"diff_weight\"] = (\n",
    "    monthly_full.groupby(\"item_id\")[\"total_weight\"].diff()\n",
    ")\n",
    "\n",
    "monthly_full[\"sign_value\"]  = np.sign(monthly_full[\"diff_value\"].fillna(0))\n",
    "monthly_full[\"sign_weight\"] = np.sign(monthly_full[\"diff_weight\"].fillna(0))\n",
    "\n",
    "# lag features (1~3)\n",
    "for col in [\"total_value\", \"total_weight\", \"total_quantity\",\n",
    "            \"log_value\", \"log_weight\"]:\n",
    "    for lag in [1, 2, 3]:\n",
    "        new_col = f\"{col}_lag{lag}\"\n",
    "        monthly_full[new_col] = (\n",
    "            monthly_full.groupby(\"item_id\")[col].shift(lag)\n",
    "        )\n",
    "\n",
    "# ============================================================\n",
    "# 7. Ìä∏Î†åÎìú Í≥ÑÏÇ∞ Ìï®Ïàò (item-level global slope)\n",
    "# ============================================================\n",
    "def compute_trend(values: np.ndarray) -> float:\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if len(values) < 3:\n",
    "        return 0.0\n",
    "    if np.all(values == values[0]):\n",
    "        return 0.0\n",
    "    X = np.arange(len(values)).reshape(-1, 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, values)\n",
    "    return float(lr.coef_[0])\n",
    "\n",
    "trend_log = []\n",
    "trend_raw = []\n",
    "\n",
    "for _, sub in monthly_full.groupby(\"item_id\"):\n",
    "    vals_log = sub[\"log_value\"].values\n",
    "    vals_raw = sub[\"total_value\"].values\n",
    "    slope_log = compute_trend(vals_log)\n",
    "    slope_raw = compute_trend(vals_raw)\n",
    "    trend_log.extend([slope_log] * len(sub))\n",
    "    trend_raw.extend([slope_raw] * len(sub))\n",
    "\n",
    "monthly_full[\"trend_log_value\"] = trend_log\n",
    "monthly_full[\"trend_value\"] = trend_raw\n",
    "\n",
    "# ============================================================\n",
    "# 8. Seasonality (global / hs4 / itemÎ≥Ñ)\n",
    "#   - month-of-year Í∏∞Ï§Ä\n",
    "# ============================================================\n",
    "# Ï†ÑÏ≤¥ ÏãúÏ¶åÏÑ± (monthÎ≥Ñ ÌèâÍ∑† / Ï†ÑÏ≤¥ ÌèâÍ∑†)\n",
    "global_mean = monthly_full[\"total_value\"].mean()\n",
    "month_mean = monthly_full.groupby(\"month\")[\"total_value\"].mean()\n",
    "season_global = (month_mean / global_mean).to_dict()\n",
    "\n",
    "monthly_full[\"seasonality_global\"] = monthly_full[\"month\"].map(season_global)\n",
    "\n",
    "# HS4 Í∏∞Î∞ò ÏãúÏ¶åÏÑ±\n",
    "hs4_month = (\n",
    "    monthly_full.groupby([\"hs4\", \"month\"])[\"total_value\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"total_value\": \"hs4_month_avg\"})\n",
    ")\n",
    "\n",
    "hs4_global = (\n",
    "    monthly_full.groupby(\"hs4\")[\"total_value\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"total_value\": \"hs4_global_mean\"})\n",
    ")\n",
    "\n",
    "hs4_season = hs4_month.merge(hs4_global, on=\"hs4\", how=\"left\")\n",
    "hs4_season[\"hs4_season_idx\"] = (\n",
    "    hs4_season[\"hs4_month_avg\"] / hs4_season[\"hs4_global_mean\"].replace(0, np.nan)\n",
    ")\n",
    "\n",
    "monthly_full = monthly_full.merge(\n",
    "    hs4_season[[\"hs4\", \"month\", \"hs4_season_idx\"]],\n",
    "    on=[\"hs4\", \"month\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# itemÎ≥Ñ ÏãúÏ¶åÏÑ± (ÏïÑÏù¥ÌÖúÎ≥Ñ month-of-year Ìå®ÌÑ¥)\n",
    "item_month = (\n",
    "    monthly_full.groupby([\"item_id\", \"month\"])[\"total_value\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"total_value\": \"item_month_avg\"})\n",
    ")\n",
    "\n",
    "item_global = (\n",
    "    monthly_full.groupby(\"item_id\")[\"total_value\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"total_value\": \"item_global_mean\"})\n",
    ")\n",
    "\n",
    "item_season = item_month.merge(item_global, on=\"item_id\", how=\"left\")\n",
    "item_season[\"item_season_idx\"] = (\n",
    "    item_season[\"item_month_avg\"] / item_season[\"item_global_mean\"].replace(0, np.nan)\n",
    ")\n",
    "\n",
    "monthly_full = monthly_full.merge(\n",
    "    item_season[[\"item_id\", \"month\", \"item_season_idx\"]],\n",
    "    on=[\"item_id\", \"month\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9. value-weight cluster (KMeans, log Í∏∞Î∞ò)\n",
    "# ============================================================\n",
    "mask_pos = (monthly_full[\"total_value\"] > 0) & (monthly_full[\"total_weight\"] > 0)\n",
    "X = monthly_full.loc[mask_pos, [\"log_weight\", \"log_value\"]].values\n",
    "\n",
    "if len(X) > 0:\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    monthly_full[\"cluster_wv\"] = -1\n",
    "    monthly_full.loc[mask_pos, \"cluster_wv\"] = cluster_labels\n",
    "else:\n",
    "    monthly_full[\"cluster_wv\"] = -1\n",
    "\n",
    "monthly_full[\"cluster_wv\"] = monthly_full[\"cluster_wv\"].astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# 10. item-level Ï†ïÏ†Å ÏöîÏïΩ (CV, Í∏∞Í∞Ñ, active months, rare flag)\n",
    "# ============================================================\n",
    "item_group = monthly_full.groupby(\"item_id\")\n",
    "\n",
    "total_sum = item_group[\"total_value\"].sum()\n",
    "total_mean = item_group[\"total_value\"].mean()\n",
    "total_std = item_group[\"total_value\"].std().fillna(0)\n",
    "\n",
    "value_cv = (total_std / total_mean.replace(0, np.nan)).fillna(0)\n",
    "\n",
    "active_months = item_group[\"event\"].sum()\n",
    "first_date = item_group[\"ym\"].min()\n",
    "last_date = item_group[\"ym\"].max()\n",
    "\n",
    "item_static = pd.DataFrame({\n",
    "    \"item_id\": total_sum.index,\n",
    "    \"total_value_sum\": total_sum.values,\n",
    "    \"total_value_mean\": total_mean.values,\n",
    "    \"total_value_std\": total_std.values,\n",
    "    \"value_cv\": value_cv.values,\n",
    "    \"active_months\": active_months.values,\n",
    "    \"first_date\": first_date.values,\n",
    "    \"last_date\": last_date.values,\n",
    "})\n",
    "\n",
    "# rare item flag (ÌïòÏúÑ 5% Í∏∞Ï§Ä)\n",
    "threshold = total_sum.quantile(0.05)\n",
    "rare_items = total_sum[total_sum < threshold].index\n",
    "monthly_full[\"rare_item_flag\"] = monthly_full[\"item_id\"].isin(rare_items).astype(int)\n",
    "\n",
    "# type / hs Ï†ïÎ≥¥ÎèÑ summaryÏóê Î∂ôÏù¥Í∏∞\n",
    "item_meta = (\n",
    "    monthly_full.groupby(\"item_id\")[[\"hs2\", \"hs3\", \"hs4\", \"type\"]]\n",
    "                .agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0])\n",
    "                .reset_index()\n",
    ")\n",
    "\n",
    "item_summary = item_static.merge(item_meta, on=\"item_id\", how=\"left\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. EDAÏö© pivot (item √ó ym, value matrix)\n",
    "# ============================================================\n",
    "pivot_value = (\n",
    "    monthly_full.pivot(index=\"item_id\", columns=\"ym\", values=\"total_value\")\n",
    "               .sort_index()\n",
    ")\n",
    "\n",
    "print(\"üìå pivot_value shape:\", pivot_value.shape)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE\n",
    "# ============================================================\n",
    "df.to_csv(CLEAN_PATH, index=False)\n",
    "monthly_full.to_csv(MONTHLY_PATH, index=False)\n",
    "pivot_value.to_csv(PIVOT_VALUE_PATH)\n",
    "item_summary.to_csv(ITEM_SUMMARY_PATH, index=False)\n",
    "\n",
    "print(\"üéâ Saved:\")\n",
    "print(\" -\", CLEAN_PATH)\n",
    "print(\" -\", MONTHLY_PATH)\n",
    "print(\" -\", PIVOT_VALUE_PATH)\n",
    "print(\" -\", ITEM_SUMMARY_PATH)\n",
    "print(\"üî• preprocess_v3_eda ÏôÑÏÑ±!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28e4ba-87ef-4d8c-99a0-06d2aced14f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
