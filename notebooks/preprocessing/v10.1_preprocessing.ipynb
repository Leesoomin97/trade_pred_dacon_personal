{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5c09af-1ef9-416d-a26b-a5f551debfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD RAW] /data/ephemeral/home/data/raw/train.csv\n",
      "[SAVE] train_month(B안) → /data/ephemeral/home/data/processed/train_month.csv  (shape=(3776, 5))\n",
      "[SAVE] monthly pivot → /data/ephemeral/home/data/processed/v10_pairs/monthly_pivot_v10.csv  (shape=(43, 100))\n",
      "[PAIR-MINE] candidate items: 100\n",
      "[PAIR-MINE] mined 8556 base pairs (no threshold filter yet)\n",
      "[TH=0.250] pairs=4864, avg|corr|=0.3717, avg_lag=3.57, max_lag_share=0.195\n",
      "[TH=0.280] pairs=3941, avg|corr|=0.3969, avg_lag=3.56, max_lag_share=0.193\n",
      "[TH=0.300] pairs=3405, avg|corr|=0.4137, avg_lag=3.54, max_lag_share=0.188\n",
      "[TH=0.320] pairs=2927, avg|corr|=0.4307, avg_lag=3.56, max_lag_share=0.193\n",
      "[TH=0.350] pairs=2289, avg|corr|=0.4576, avg_lag=3.55, max_lag_share=0.187\n",
      "[TH=0.380] pairs=1796, avg|corr|=0.4833, avg_lag=3.54, max_lag_share=0.180\n",
      "[TH=0.400] pairs=1513, avg|corr|=0.5008, avg_lag=3.57, max_lag_share=0.187\n",
      "\n",
      "[THRESHOLD STATS]\n",
      "   threshold  pair_count  avg_abs_corr   avg_lag  max_lag_share   pc_norm  \\\n",
      "0       0.25        4864      0.371742  3.570518       0.194901  1.000000   \n",
      "1       0.28        3941      0.396852  3.562548       0.193098  0.724560   \n",
      "2       0.30        3405      0.413671  3.537151       0.188253  0.564608   \n",
      "3       0.32        2927      0.430676  3.559959       0.193030  0.421964   \n",
      "4       0.35        2289      0.457585  3.546090       0.186981  0.231573   \n",
      "5       0.38        1796      0.483306  3.541203       0.180401  0.084452   \n",
      "6       0.40        1513      0.500830  3.571051       0.187046  0.000000   \n",
      "\n",
      "    ac_norm  raw_score  penalty  final_score  \n",
      "0  0.000000   0.400000      0.0     0.400000  \n",
      "1  0.194518   0.406535      0.0     0.406535  \n",
      "2  0.324808   0.420728      0.0     0.420728  \n",
      "3  0.456536   0.442707      0.0     0.442707  \n",
      "4  0.664990   0.491623      0.0     0.491623  \n",
      "5  0.864242   0.552326      0.0     0.552326  \n",
      "6  1.000000   0.600000      0.0     0.600000  \n",
      "\n",
      "[BEST] threshold=0.400 (final_score=0.6000, pairs=1513, avg|corr|=0.5008)\n",
      "[SAVE] threshold stats → /data/ephemeral/home/data/processed/v10_pairs/threshold_stats_v10.csv\n",
      "[SAVE] best pairs (th=0.400) → /data/ephemeral/home/data/processed/v10_pairs/pairs_v10_th40.csv (rows=1513)\n",
      "[SAVE] best pairs alias → /data/ephemeral/home/data/processed/v10_pairs/pairs_v10_best.csv\n",
      "✅ pair_generate_v10_best DONE\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# pair_generate_v10_best.py\n",
    "# - raw/train.csv → train_month.csv (B안: hs4 포함, type 제외)\n",
    "# - train_month → pivot (ym × item)\n",
    "# - threshold sweep (0.25~0.40)로 best threshold 자동 산정\n",
    "# - best threshold로 pairs_v10_thXX.csv + pairs_v10_best.csv 저장\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# 0. PATH\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parents[1] / \"data\"\n",
    "\n",
    "RAW_PATH          = DATA_DIR / \"raw\" / \"train.csv\"\n",
    "PROCESSED_DIR     = DATA_DIR / \"processed\"\n",
    "TRAIN_MONTH_PATH  = PROCESSED_DIR / \"train_month.csv\"  # B안 결과 (팀원 코드 호환)\n",
    "OUT_DIR           = PROCESSED_DIR / \"v10_pairs\"\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 파일들\n",
    "PIVOT_PATH        = OUT_DIR / \"monthly_pivot_v10.csv\"\n",
    "THRESH_STAT_PATH  = OUT_DIR / \"threshold_stats_v10.csv\"\n",
    "BEST_PAIR_PATH    = OUT_DIR / \"pairs_v10_best.csv\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. raw → train_month(B안) + pivot 생성\n",
    "#    - B안: (item_id, year, month, hs4, value)\n",
    "# ============================================================\n",
    "def build_train_month_and_pivot(\n",
    "    raw_path: Path,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    입력: raw/train.csv\n",
    "    출력:\n",
    "      - train_month: item_id, year, month, hs4, value\n",
    "      - monthly: item_id, ym, value_sum\n",
    "      - pivot: index=ym, columns=item_id, values=value_sum\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"[LOAD RAW] {raw_path}\")\n",
    "    df = pd.read_csv(raw_path)\n",
    "\n",
    "    # 기본 타입 정리\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "    df[\"hs4\"] = df[\"hs4\"].astype(str).str.zfill(4)\n",
    "    df[\"value\"] = df[\"value\"].astype(float)\n",
    "\n",
    "    # ym 생성\n",
    "    df[\"ym\"] = pd.to_datetime(\n",
    "        df[\"year\"].astype(str) + \"-\" +\n",
    "        df[\"month\"].astype(str) + \"-01\"\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1) B안 train_month (hs4 포함)\n",
    "    #    - seq, weight, quantity, type 제거\n",
    "    #    - 월별 value 합계\n",
    "    # -------------------------------\n",
    "    group_cols = [\"item_id\", \"hs4\", \"year\", \"month\"]\n",
    "\n",
    "    train_month = (\n",
    "        df.groupby(group_cols, as_index=False)[\"value\"]\n",
    "          .sum()\n",
    "    )\n",
    "\n",
    "    # 팀원 v3와 완전 호환되는 형태 유지 (train_month.csv)\n",
    "    train_month.to_csv(TRAIN_MONTH_PATH, index=False)\n",
    "    print(f\"[SAVE] train_month(B안) → {TRAIN_MONTH_PATH}  (shape={train_month.shape})\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) monthly (item_id × ym)\n",
    "    # -------------------------------\n",
    "    monthly = (\n",
    "        df.groupby([\"item_id\", \"ym\"], as_index=False)[\"value\"]\n",
    "          .sum()\n",
    "          .rename(columns={\"value\": \"value_sum\"})\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3) pivot (ym × item_id)\n",
    "    # -------------------------------\n",
    "    pivot = (\n",
    "        monthly.pivot_table(\n",
    "            index=\"ym\",\n",
    "            columns=\"item_id\",\n",
    "            values=\"value_sum\",\n",
    "            aggfunc=\"sum\",\n",
    "        )\n",
    "        .sort_index()\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    pivot.to_csv(PIVOT_PATH)\n",
    "    print(f\"[SAVE] monthly pivot → {PIVOT_PATH}  (shape={pivot.shape})\")\n",
    "\n",
    "    return train_month, monthly, pivot\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. corr 기반 pair mining: base_pairs 생성\n",
    "#    (once 계산 → threshold별 filter만)\n",
    "# ============================================================\n",
    "def safe_corr(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"분산=0 예외를 처리한 피어슨 상관계수.\"\"\"\n",
    "    if x.std() == 0 or y.std() == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "\n",
    "def mine_all_pairs(\n",
    "    pivot: pd.DataFrame,\n",
    "    max_lag: int = 6,\n",
    "    min_nonzero: int = 8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    팀원 v3 로직에서 threshold만 제거한 버전:\n",
    "    - 모든 (leader, follower) 조합에 대해\n",
    "      best_lag, max_corr 계산\n",
    "    - corr_threshold는 나중에 filter에서 사용\n",
    "    \"\"\"\n",
    "\n",
    "    items = pivot.columns.tolist()\n",
    "    pairs: List[Dict[str, float]] = []\n",
    "\n",
    "    print(f\"[PAIR-MINE] candidate items: {len(items)}\")\n",
    "    values_np = pivot.values  # (T, N)\n",
    "\n",
    "    for i, leader in enumerate(items):\n",
    "        leader_series = values_np[:, i].astype(float)\n",
    "        if np.count_nonzero(leader_series) < min_nonzero:\n",
    "            continue\n",
    "\n",
    "        for j, follower in enumerate(items):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            follower_series = values_np[:, j].astype(float)\n",
    "            if np.count_nonzero(follower_series) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            best_lag = None\n",
    "            best_corr = 0.0\n",
    "\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if len(leader_series) <= lag:\n",
    "                    break\n",
    "\n",
    "                x = leader_series[:-lag]\n",
    "                y = follower_series[lag:]\n",
    "                corr = safe_corr(x, y)\n",
    "\n",
    "                if abs(corr) > abs(best_corr):\n",
    "                    best_corr = corr\n",
    "                    best_lag = lag\n",
    "\n",
    "            if best_lag is None:\n",
    "                continue\n",
    "\n",
    "            pairs.append(\n",
    "                {\n",
    "                    \"leading_item_id\": leader,\n",
    "                    \"following_item_id\": follower,\n",
    "                    \"best_lag\": int(best_lag),\n",
    "                    \"max_corr\": float(best_corr),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    base_pairs = pd.DataFrame(pairs)\n",
    "    print(f\"[PAIR-MINE] mined {len(base_pairs)} base pairs (no threshold filter yet)\")\n",
    "    return base_pairs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. threshold sweep + heuristic 점수로 best threshold 선택\n",
    "# ============================================================\n",
    "def evaluate_thresholds(\n",
    "    base_pairs: pd.DataFrame,\n",
    "    thresholds: List[float],\n",
    ") -> Tuple[pd.DataFrame, float]:\n",
    "    \"\"\"\n",
    "    thresholds 리스트에 대해:\n",
    "      - pair_count\n",
    "      - avg_abs_corr\n",
    "      - avg_lag\n",
    "      - max_lag_share\n",
    "    를 계산하고, heuristic 점수로 best threshold 선택.\n",
    "    \"\"\"\n",
    "\n",
    "    stats = []\n",
    "\n",
    "    for th in thresholds:\n",
    "        pairs_th = base_pairs[base_pairs[\"max_corr\"].abs() >= th].copy()\n",
    "        pair_count = len(pairs_th)\n",
    "\n",
    "        if pair_count == 0:\n",
    "            print(f\"[TH={th:.3f}] no pairs, skip\")\n",
    "            continue\n",
    "\n",
    "        avg_abs_corr = pairs_th[\"max_corr\"].abs().mean()\n",
    "        avg_lag = pairs_th[\"best_lag\"].mean()\n",
    "\n",
    "        lag_dist = pairs_th[\"best_lag\"].value_counts(normalize=True)\n",
    "        max_lag_share = float(lag_dist.max())\n",
    "\n",
    "        stats.append(\n",
    "            {\n",
    "                \"threshold\": th,\n",
    "                \"pair_count\": pair_count,\n",
    "                \"avg_abs_corr\": avg_abs_corr,\n",
    "                \"avg_lag\": avg_lag,\n",
    "                \"max_lag_share\": max_lag_share,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[TH={th:.3f}] pairs={pair_count}, \"\n",
    "            f\"avg|corr|={avg_abs_corr:.4f}, avg_lag={avg_lag:.2f}, \"\n",
    "            f\"max_lag_share={max_lag_share:.3f}\"\n",
    "        )\n",
    "\n",
    "    if not stats:\n",
    "        raise ValueError(\"모든 threshold 후보에서 pair가 생성되지 않았습니다.\")\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "\n",
    "    # ---------------------------\n",
    "    # heuristic scoring\n",
    "    #  - corr, pair_count 둘 다 normalize 후 가중합\n",
    "    #  - 너무 많거나 너무 적은 pair에는 penalty\n",
    "    #  - 특정 lag에 몰리면 penalty\n",
    "    # ---------------------------\n",
    "    pc = stats_df[\"pair_count\"]\n",
    "    ac = stats_df[\"avg_abs_corr\"]\n",
    "\n",
    "    pc_norm = (pc - pc.min()) / (pc.max() - pc.min() + 1e-9)\n",
    "    ac_norm = (ac - ac.min()) / (ac.max() - ac.min() + 1e-9)\n",
    "\n",
    "    raw_score = 0.6 * ac_norm + 0.4 * pc_norm\n",
    "    penalty = np.zeros(len(stats_df))\n",
    "\n",
    "    # pair 수가 너무 많거나 너무 적으면 penalty\n",
    "    for idx, row in stats_df.iterrows():\n",
    "        if row[\"pair_count\"] > 5000:\n",
    "            penalty[idx] += 0.3\n",
    "        elif row[\"pair_count\"] < 800:\n",
    "            penalty[idx] += 0.3\n",
    "\n",
    "        # lag 한쪽으로 심하게 몰리면 penalty\n",
    "        if row[\"max_lag_share\"] > 0.8:\n",
    "            penalty[idx] += 0.2\n",
    "\n",
    "    final_score = raw_score - penalty\n",
    "\n",
    "    stats_df[\"pc_norm\"] = pc_norm\n",
    "    stats_df[\"ac_norm\"] = ac_norm\n",
    "    stats_df[\"raw_score\"] = raw_score\n",
    "    stats_df[\"penalty\"] = penalty\n",
    "    stats_df[\"final_score\"] = final_score\n",
    "\n",
    "    # best threshold\n",
    "    best_idx = int(final_score.idxmax())\n",
    "    best_th = float(stats_df.loc[best_idx, \"threshold\"])\n",
    "\n",
    "    print(\"\\n[THRESHOLD STATS]\")\n",
    "    print(stats_df.sort_values(\"threshold\"))\n",
    "\n",
    "    print(\n",
    "        f\"\\n[BEST] threshold={best_th:.3f} \"\n",
    "        f\"(final_score={stats_df.loc[best_idx, 'final_score']:.4f}, \"\n",
    "        f\"pairs={int(stats_df.loc[best_idx, 'pair_count'])}, \"\n",
    "        f\"avg|corr|={stats_df.loc[best_idx, 'avg_abs_corr']:.4f})\"\n",
    "    )\n",
    "\n",
    "    # 저장\n",
    "    stats_df.to_csv(THRESH_STAT_PATH, index=False)\n",
    "    print(f\"[SAVE] threshold stats → {THRESH_STAT_PATH}\")\n",
    "\n",
    "    return stats_df, best_th\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. main: raw → train_month + pivot → base_pairs → best threshold → pairs 저장\n",
    "# ============================================================\n",
    "def main():\n",
    "    # 1) raw → train_month(B안) + monthly + pivot\n",
    "    train_month, monthly, pivot = build_train_month_and_pivot(RAW_PATH)\n",
    "\n",
    "    # 2) 모든 pair mining (threshold 없이)\n",
    "    base_pairs = mine_all_pairs(\n",
    "        pivot,\n",
    "        max_lag=6,\n",
    "        min_nonzero=8,\n",
    "    )\n",
    "\n",
    "    # 3) threshold candidates (팀원이 쓰던 구간 그대로)\n",
    "    threshold_candidates = [0.25, 0.28, 0.30, 0.32, 0.35, 0.38, 0.40]\n",
    "\n",
    "    # 4) threshold sweep + heuristic 선택\n",
    "    stats_df, best_th = evaluate_thresholds(\n",
    "        base_pairs,\n",
    "        threshold_candidates,\n",
    "    )\n",
    "\n",
    "    # 5) best_th에 맞는 pairs 필터링\n",
    "    best_pairs = base_pairs[base_pairs[\"max_corr\"].abs() >= best_th].copy()\n",
    "    best_pairs = best_pairs.reset_index(drop=True)\n",
    "\n",
    "    # 6) 저장\n",
    "    best_th_tag = int(best_th * 100)\n",
    "    best_pairs_path_tag = OUT_DIR / f\"pairs_v10_th{best_th_tag:02d}.csv\"\n",
    "\n",
    "    best_pairs.to_csv(best_pairs_path_tag, index=False)\n",
    "    best_pairs.to_csv(BEST_PAIR_PATH, index=False)\n",
    "\n",
    "    print(f\"[SAVE] best pairs (th={best_th:.3f}) → {best_pairs_path_tag} (rows={len(best_pairs)})\")\n",
    "    print(f\"[SAVE] best pairs alias → {BEST_PAIR_PATH}\")\n",
    "    print(\"✅ pair_generate_v10_best DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6795e-8d25-418e-b071-37d5916e04b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
