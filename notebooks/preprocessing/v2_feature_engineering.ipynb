{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c821701-45ac-4440-9a3e-8d5e7682016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üì¶ Feature Engineering (FE) + pair_train ‚Äî v2 SAFE\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87350fe-fb86-4301-9cd6-6f6c62c9ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned datasets...\n",
      "‚úî Loaded: (10535, 9) (3734, 8)\n",
      "pivot_item: (100, 43)\n",
      "pivot_hs3: (54, 43)\n",
      "‚úî meta feature done: (100, 4)\n",
      "‚úî single HS3 leader done: (100, 4)\n",
      "‚úî multi-leader lag done: (95, 2)\n",
      "üéâ Final FE v2: (100, 8)\n",
      "    item_id  zero_ratio    volatility        cv lead_hs3  best_lag_hs3  \\\n",
      "0  AANGBULD    0.325581  1.435857e+05  1.708994      300           3.0   \n",
      "1  AHMDUILJ    0.000000  4.551154e+04  0.358842      600           6.0   \n",
      "2  ANWUJOKX    0.813953  2.034624e+04  2.497477      520           3.0   \n",
      "3  APQGTRMF    0.023256  2.095910e+05  0.814870      720           6.0   \n",
      "4  ATLDMDBO    0.000000  3.234730e+07  0.539145      281           3.0   \n",
      "\n",
      "   corr_hs3  multi_leader_lag  \n",
      "0  0.592394          3.030900  \n",
      "1  0.409002          4.000270  \n",
      "2  0.636641          2.956122  \n",
      "3  0.571589          1.323089  \n",
      "4  0.728171          3.253572  \n",
      "üíæ Saved FE v2 to: /data/ephemeral/home/data/processed/v2_features_basic.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0Ô∏è‚É£ Path & Load\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "CLEAN_PATH = BASE_DIR.parents[1] / \"data\" / \"interim\" / \"train_clean.csv\"\n",
    "MONTHLY_PATH = BASE_DIR.parents[1] / \"data\" / \"processed\" / \"train_monthly.csv\"\n",
    "\n",
    "print(\"Loading cleaned datasets...\")\n",
    "df = pd.read_csv(CLEAN_PATH)\n",
    "monthly = pd.read_csv(MONTHLY_PATH)\n",
    "print(\"‚úî Loaded:\", df.shape, monthly.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ HS ÏΩîÎìú & YM ÏÉùÏÑ± (Ìïú Î≤àÎßå!)\n",
    "# ------------------------------------------------------------\n",
    "monthly[\"hs3\"] = monthly[\"hs4\"].astype(str).str[:3]\n",
    "monthly[\"ym\"] = pd.to_datetime(\n",
    "    monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ pivot_item / pivot_hs3 ÏÉùÏÑ±\n",
    "# ------------------------------------------------------------\n",
    "pivot_item = monthly.pivot(\n",
    "    index=\"item_id\", columns=\"ym\", values=\"total_value\"\n",
    ").fillna(0.0)\n",
    "\n",
    "monthly_hs3 = (\n",
    "    monthly.groupby([\"hs3\", \"ym\"], as_index=False)[\"total_value\"].sum()\n",
    ")\n",
    "pivot_hs3 = monthly_hs3.pivot(\n",
    "    index=\"hs3\", columns=\"ym\", values=\"total_value\"\n",
    ").fillna(0.0)\n",
    "\n",
    "print(\"pivot_item:\", pivot_item.shape)\n",
    "print(\"pivot_hs3:\", pivot_hs3.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ zero_ratio / volatility / CV (item Îã®ÏúÑ 1 row)\n",
    "# ------------------------------------------------------------\n",
    "def compute_zero_vol(series: pd.Series):\n",
    "    arr = series.values.astype(float)\n",
    "    zero_ratio = (arr == 0).mean()\n",
    "    vol = arr.std()\n",
    "    cv = arr.std() / (arr.mean() + 1e-9)\n",
    "    return zero_ratio, vol, cv\n",
    "\n",
    "records = []\n",
    "for item in pivot_item.index:\n",
    "    zr, vol, cv = compute_zero_vol(pivot_item.loc[item])\n",
    "    records.append([item, zr, vol, cv])\n",
    "\n",
    "meta = pd.DataFrame(records, columns=[\"item_id\", \"zero_ratio\", \"volatility\", \"cv\"])\n",
    "print(\"‚úî meta feature done:\", meta.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ HS3 ‚Üí HS4 single best leader (itemÎãπ 1 row)\n",
    "# ------------------------------------------------------------\n",
    "pairs_hs3 = []\n",
    "\n",
    "for hs3 in pivot_hs3.index:\n",
    "    leader_s = pivot_hs3.loc[hs3].values.astype(float)\n",
    "    for item in pivot_item.index:\n",
    "        follower_s = pivot_item.loc[item].values.astype(float)\n",
    "\n",
    "        best_lag = None\n",
    "        best_corr = -999.0\n",
    "\n",
    "        for lag in range(1, 7):\n",
    "            if len(leader_s) <= lag:\n",
    "                continue\n",
    "            corr = np.corrcoef(leader_s[:-lag], follower_s[lag:])[0, 1]\n",
    "            if corr > best_corr:\n",
    "                best_corr = corr\n",
    "                best_lag = lag\n",
    "\n",
    "        pairs_hs3.append([hs3, item, best_lag, best_corr])\n",
    "\n",
    "pairs_hs3 = pd.DataFrame(\n",
    "    pairs_hs3,\n",
    "    columns=[\"lead_hs3\", \"item_id\", \"best_lag_hs3\", \"corr_hs3\"],\n",
    ")\n",
    "\n",
    "# item_idÎ≥ÑÎ°ú corr_hs3 ÏµúÍ≥† 1Í∞úÎßå ÎÇ®Í∏∞Í∏∞\n",
    "pairs_hs3_best = (\n",
    "    pairs_hs3.sort_values(\"corr_hs3\", ascending=False)\n",
    "             .groupby(\"item_id\")\n",
    "             .head(1)\n",
    ")\n",
    "\n",
    "print(\"‚úî single HS3 leader done:\", pairs_hs3_best.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ HS4 multi-leader weighted lag (top3 ‚Üí Îã®ÏùºÍ∞í)\n",
    "# ------------------------------------------------------------\n",
    "def find_pairs_item(pivot, max_lag=6, corr_threshold=0.3):\n",
    "    items = pivot.index.to_list()\n",
    "    months = pivot.columns\n",
    "    n_months = len(months)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for A in items:\n",
    "        x = pivot.loc[A].values.astype(float)\n",
    "        if np.count_nonzero(x) < 6:\n",
    "            continue\n",
    "\n",
    "        for B in items:\n",
    "            if A == B:\n",
    "                continue\n",
    "\n",
    "            y = pivot.loc[B].values.astype(float)\n",
    "            if np.count_nonzero(y) < 6:\n",
    "                continue\n",
    "\n",
    "            best_corr = -999.0\n",
    "            best_lag = None\n",
    "\n",
    "            for lag in range(1, max_lag+1):\n",
    "                if n_months <= lag:\n",
    "                    continue\n",
    "                corr = np.corrcoef(x[:-lag], y[lag:])[0, 1]\n",
    "                if corr > best_corr:\n",
    "                    best_corr = corr\n",
    "                    best_lag = lag\n",
    "\n",
    "            if best_corr >= corr_threshold and best_lag is not None:\n",
    "                res.append([A, B, best_lag, best_corr])\n",
    "\n",
    "    return pd.DataFrame(res, columns=[\"leader\", \"follower\", \"lag\", \"corr\"])\n",
    "\n",
    "\n",
    "pairs_hs4 = find_pairs_item(pivot_item, corr_threshold=0.3)\n",
    "\n",
    "# followerÎ≥Ñ ÏÉÅÏúÑ 3Í∞úÎßå\n",
    "top3 = (\n",
    "    pairs_hs4.sort_values(\"corr\", ascending=False)\n",
    "             .groupby(\"follower\")\n",
    "             .head(3)\n",
    ")\n",
    "\n",
    "def weighted_lag(df):\n",
    "    return np.average(df[\"lag\"], weights=df[\"corr\"])\n",
    "\n",
    "multi_leader_lag = (\n",
    "    top3.groupby(\"follower\")\n",
    "        .apply(weighted_lag)\n",
    "        .reset_index(name=\"multi_leader_lag\")\n",
    ")\n",
    "\n",
    "print(\"‚úî multi-leader lag done:\", multi_leader_lag.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ ÏµúÏ¢Ö FE v2 (itemÎãπ 1 row) ÏÉùÏÑ± & Ï†ÄÏû•\n",
    "# ------------------------------------------------------------\n",
    "FE = (\n",
    "    meta\n",
    "    .merge(pairs_hs3_best, on=\"item_id\", how=\"left\")\n",
    "    .merge(multi_leader_lag, left_on=\"item_id\", right_on=\"follower\", how=\"left\")\n",
    ")\n",
    "\n",
    "FE = FE.drop(columns=[\"follower\"], errors=\"ignore\")\n",
    "\n",
    "print(\"üéâ Final FE v2:\", FE.shape)\n",
    "print(FE.head())\n",
    "\n",
    "FE_OUT_PATH = BASE_DIR.parents[1] / \"data\" / \"processed\" / \"v2_features_basic.csv\"\n",
    "FE_OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "FE.to_csv(FE_OUT_PATH, index=False)\n",
    "print(f\"üíæ Saved FE v2 to: {FE_OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53128cad-b137-4807-8340-17c5e2417786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Create pair_train from pivot_item...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî pair candidates: (8930, 4)\n",
      "‚úî pair_train: (343354, 8)\n",
      "üíæ Saved pair_train v2 to: /data/ephemeral/home/data/processed/pair_train_v2.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ pair_train ÏÉùÏÑ± (baseline self-supervised)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüß© Create pair_train from pivot_item...\")\n",
    "\n",
    "def safe_corr(x, y):\n",
    "    if np.std(x) == 0 or np.std(y) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "months = pivot_item.columns.to_list()\n",
    "n_months = len(months)\n",
    "\n",
    "pairs = []\n",
    "for leader in tqdm(pivot_item.index):\n",
    "    x = pivot_item.loc[leader].values.astype(float)\n",
    "    if np.count_nonzero(x) < 6:\n",
    "        continue\n",
    "\n",
    "    for follower in pivot_item.index:\n",
    "        if follower == leader:\n",
    "            continue\n",
    "\n",
    "        y = pivot_item.loc[follower].values.astype(float)\n",
    "        if np.count_nonzero(y) < 6:\n",
    "            continue\n",
    "\n",
    "        best_corr = 0.0\n",
    "        best_lag = None\n",
    "\n",
    "        for lag in range(1, 7):\n",
    "            if n_months <= lag:\n",
    "                continue\n",
    "\n",
    "            corr = safe_corr(x[:-lag], y[lag:])\n",
    "            if abs(corr) > abs(best_corr):\n",
    "                best_corr = corr\n",
    "                best_lag = lag\n",
    "\n",
    "        if best_lag is not None:\n",
    "            pairs.append([leader, follower, best_lag, best_corr])\n",
    "\n",
    "pair_df = pd.DataFrame(\n",
    "    pairs,\n",
    "    columns=[\"leading_item_id\", \"following_item_id\", \"best_lag\", \"max_corr\"],\n",
    ")\n",
    "\n",
    "print(\"‚úî pair candidates:\", pair_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ pair_train target ÏÉùÏÑ±\n",
    "# ------------------------------------------------------------\n",
    "rows = []\n",
    "for row in pair_df.itertuples():\n",
    "    L = row.leading_item_id\n",
    "    F = row.following_item_id\n",
    "    lag = int(row.best_lag)\n",
    "    corr = float(row.max_corr)\n",
    "\n",
    "    xs = pivot_item.loc[L].values.astype(float)\n",
    "    ys = pivot_item.loc[F].values.astype(float)\n",
    "\n",
    "    for t in range(max(lag, 1), n_months - 1):\n",
    "        rows.append({\n",
    "            \"leading_item_id\": L,\n",
    "            \"following_item_id\": F,\n",
    "            \"b_t\": ys[t],\n",
    "            \"b_t_1\": ys[t - 1],\n",
    "            \"a_t_lag\": xs[t - lag],\n",
    "            \"max_corr\": corr,\n",
    "            \"best_lag\": lag,\n",
    "            \"target\": ys[t + 1],\n",
    "        })\n",
    "\n",
    "pair_train = pd.DataFrame(rows)\n",
    "print(\"‚úî pair_train:\", pair_train.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ pair_train ‚®â FE merge\n",
    "# ------------------------------------------------------------\n",
    "pair_train = pair_train.merge(\n",
    "    FE,\n",
    "    left_on=\"following_item_id\",\n",
    "    right_on=\"item_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "pair_train = pair_train.drop(columns=[\"item_id\"], errors=\"ignore\")\n",
    "\n",
    "PAIR_OUT_PATH = BASE_DIR.parents[1] / \"data\" / \"processed\" / \"pair_train_v2.csv\"\n",
    "PAIR_OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "pair_train.to_csv(PAIR_OUT_PATH, index=False)\n",
    "print(f\"üíæ Saved pair_train v2 to: {PAIR_OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67faba2-55d8-4194-a17a-e46970e5536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
