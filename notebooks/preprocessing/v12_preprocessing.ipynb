{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2453277-0161-460a-a8a7-7c42e7c2fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAIR] base_pairs: 8556\n",
      "[EDA] pairs with EDA: (8556, 19)\n",
      "=== Random Search for filters ===\n",
      "\n",
      "[RandomSearch] Best trial:\n",
      "{'corr_min': 0.2550701486830915, 'range_max': 0.8757214695406513, 'roll_max': 0.592593042179272, 'dtw_max': 1891948412.187396, 'fvol_max': 7907435.3329712385, 'snr_min': 0.06812475041558608, 'pair_count': 2215.0, 'score': 0.516994748647272}\n",
      "Random search log saved → /data/ephemeral/home/data/processed/v10_pairs/random_search_log.csv\n",
      "\n",
      "=== Bayesian Optimization for filters ===\n",
      "\n",
      "[BayesOpt] Best params:\n",
      "{'corr_min': 0.2544451341114171, 'range_max': 0.9, 'roll_max': 0.6025480362465228, 'dtw_max': 2430743656.6125507, 'fvol_max': 6867044.62442157, 'snr_min': 0.07007691663109258}\n",
      "[BayesOpt] score=0.522587, pair_count=2234.0\n",
      "\n",
      "[FINAL PARAMS]\n",
      "{'corr_min': 0.2544451341114171, 'range_max': 0.9, 'roll_max': 0.6025480362465228, 'dtw_max': 2430743656.6125507, 'fvol_max': 6867044.62442157, 'snr_min': 0.07007691663109258}\n",
      "[FINAL] filtered pairs: 2234\n",
      "[SAVE] pairs_v10_best.csv → /data/ephemeral/home/data/processed/v10_pairs/pairs_v10_best.csv (rows=2234)\n",
      "✅ DONE\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# pair_generate_v10_best_bo.py\n",
    "#  - raw/train.csv → train_month.csv, pivot\n",
    "#  - base pair mining (lag-corr)\n",
    "#  - EDA feature 생성\n",
    "#  - (1) Random Search 로 1차 필터 탐색 (trial 수 늘림)\n",
    "#  - (2) skopt 기반 Bayesian Optimization (있으면)로 미세 조정\n",
    "#  - 최종 filter 적용된 pair만 pairs_v10_best.csv로 저장\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (옵션) Bayesian Optimization (scikit-optimize)\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    from skopt import gp_minimize\n",
    "    from skopt.space import Real\n",
    "    SKOPT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKOPT_AVAILABLE = False\n",
    "    print(\"[WARN] scikit-optimize(skopt) 미설치 → Bayesian Optimization 건너뜀\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PATH\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parents[1] / \"data\"\n",
    "\n",
    "RAW_PATH          = DATA_DIR / \"raw\" / \"train.csv\"\n",
    "PROCESSED_DIR     = DATA_DIR / \"processed\"\n",
    "TRAIN_MONTH_PATH  = PROCESSED_DIR / \"train_month.csv\"\n",
    "\n",
    "OUT_DIR           = PROCESSED_DIR / \"v10_pairs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PIVOT_PATH        = OUT_DIR / \"monthly_pivot_v10.csv\"\n",
    "BEST_PAIR_PATH    = OUT_DIR / \"pairs_v10_best.csv\"\n",
    "RS_LOG_PATH       = OUT_DIR / \"random_search_log.csv\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. Pivot + train_month(B안) 생성\n",
    "# ============================================================\n",
    "def build_train_month_and_pivot(raw_path: Path):\n",
    "    df = pd.read_csv(raw_path)\n",
    "\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "    df[\"hs4\"] = df[\"hs4\"].astype(str).str.zfill(4)\n",
    "    df[\"value\"] = df[\"value\"].astype(float)\n",
    "\n",
    "    df[\"ym\"] = pd.to_datetime(\n",
    "        df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str) + \"-01\"\n",
    "    )\n",
    "\n",
    "    # B안 train_month\n",
    "    train_month = (\n",
    "        df.groupby([\"item_id\", \"hs4\", \"year\", \"month\"], as_index=False)[\"value\"]\n",
    "          .sum()\n",
    "    )\n",
    "    train_month.to_csv(TRAIN_MONTH_PATH, index=False)\n",
    "\n",
    "    monthly = (\n",
    "        df.groupby([\"item_id\", \"ym\"], as_index=False)[\"value\"]\n",
    "          .sum()\n",
    "          .rename(columns={\"value\": \"value_sum\"})\n",
    "    )\n",
    "\n",
    "    pivot = (\n",
    "        monthly.pivot_table(index=\"ym\", columns=\"item_id\", values=\"value_sum\")\n",
    "               .sort_index()\n",
    "               .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    pivot.to_csv(PIVOT_PATH)\n",
    "    return train_month, monthly, pivot\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. base pair mining (lag-corr)\n",
    "# ============================================================\n",
    "def safe_corr(x, y):\n",
    "    if x.std() == 0 or y.std() == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "\n",
    "def mine_all_pairs(pivot, max_lag=6, min_nonzero=8):\n",
    "    values_np = pivot.values\n",
    "    items = pivot.columns.tolist()\n",
    "    pairs = []\n",
    "\n",
    "    for i, leader in enumerate(items):\n",
    "        A = values_np[:, i].astype(float)\n",
    "        if np.count_nonzero(A) < min_nonzero:\n",
    "            continue\n",
    "\n",
    "        for j, follower in enumerate(items):\n",
    "            if i == j:\n",
    "                continue\n",
    "            B = values_np[:, j].astype(float)\n",
    "            if np.count_nonzero(B) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            best_corr = 0.0\n",
    "            best_lag = None\n",
    "\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if len(A) <= lag:\n",
    "                    break\n",
    "                c = safe_corr(A[:-lag], B[lag:])\n",
    "                if abs(c) > abs(best_corr):\n",
    "                    best_corr = c\n",
    "                    best_lag = lag\n",
    "\n",
    "            if best_lag is not None:\n",
    "                pairs.append(\n",
    "                    {\n",
    "                        \"leading_item_id\": leader,\n",
    "                        \"following_item_id\": follower,\n",
    "                        \"best_lag\": best_lag,\n",
    "                        \"max_corr\": best_corr,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    base_pairs = pd.DataFrame(pairs)\n",
    "    print(f\"[PAIR] base_pairs: {len(base_pairs)}\")\n",
    "    return base_pairs\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Pure Python DTW (band 제한)\n",
    "# ============================================================\n",
    "def dtw_distance(a, b, band=20):\n",
    "    n, m = len(a), len(b)\n",
    "    dp = np.full((n + 1, m + 1), np.inf)\n",
    "    dp[0, 0] = 0.0\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        j_start = max(1, i - band)\n",
    "        j_end = min(m, i + band)\n",
    "        for j in range(j_start, j_end + 1):\n",
    "            cost = abs(a[i - 1] - b[j - 1])\n",
    "            dp[i, j] = cost + min(\n",
    "                dp[i - 1, j],\n",
    "                dp[i, j - 1],\n",
    "                dp[i - 1, j - 1],\n",
    "            )\n",
    "    return dp[n, m]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. EDA Feature 생성\n",
    "# ============================================================\n",
    "def period_corr(x, y, start, end):\n",
    "    if end > len(x):\n",
    "        return np.nan\n",
    "    xa, ya = x[start:end], y[start:end]\n",
    "    if xa.std() == 0 or ya.std() == 0:\n",
    "        return np.nan\n",
    "    return np.corrcoef(xa, ya)[0, 1]\n",
    "\n",
    "\n",
    "def trend_slope(series):\n",
    "    X = np.arange(len(series)).reshape(-1, 1)\n",
    "    lr = LinearRegression().fit(X, series)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "\n",
    "def rolling_corr_std(a, b, lag, window=12):\n",
    "    xa = a[:-lag]\n",
    "    ya = b[lag:]\n",
    "    s = pd.Series(xa).rolling(window).corr(pd.Series(ya))\n",
    "    return s.std()\n",
    "\n",
    "\n",
    "def detrended_snr(series):\n",
    "    x = np.arange(len(series))\n",
    "    lr = LinearRegression().fit(x.reshape(-1, 1), series)\n",
    "    trend = lr.predict(x.reshape(-1, 1))\n",
    "    noise = series - trend\n",
    "    return trend.var() / (noise.var() + 1e-6)\n",
    "\n",
    "\n",
    "def series_vol(x):\n",
    "    return np.std(np.diff(x))\n",
    "\n",
    "\n",
    "def attach_eda_features(pairs_df, pivot, train_raw):\n",
    "    hs4_map = (\n",
    "        train_raw[[\"item_id\", \"hs4\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"item_id\")[\"hs4\"]\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for _, r in pairs_df.iterrows():\n",
    "        A = pivot[r.leading_item_id].values\n",
    "        B = pivot[r.following_item_id].values\n",
    "        lag = int(r.best_lag)\n",
    "\n",
    "        corr_e = period_corr(A[:-lag], B[lag:], 0, 24)\n",
    "        corr_m = period_corr(A[:-lag], B[lag:], 12, 36)\n",
    "        corr_range = (\n",
    "            abs(corr_e - corr_m)\n",
    "            if (not pd.isna(corr_e) and not pd.isna(corr_m))\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        tA = trend_slope(A)\n",
    "        tB = trend_slope(B)\n",
    "\n",
    "        rc_std = rolling_corr_std(A, B, lag)\n",
    "        dtw_d = dtw_distance(A, B)\n",
    "        snr = detrended_snr(B)\n",
    "        fv = series_vol(B)\n",
    "\n",
    "        hs4_lead = hs4_map[r.leading_item_id]\n",
    "        hs4_foll = hs4_map[r.following_item_id]\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"corr_early\": corr_e,\n",
    "                \"corr_mid\": corr_m,\n",
    "                \"corr_range\": corr_range,\n",
    "                \"trend_leader\": tA,\n",
    "                \"trend_follower\": tB,\n",
    "                \"trend_match\": np.sign(tA * tB),\n",
    "                \"rollcorr_std\": rc_std,\n",
    "                \"dtw_dist\": dtw_d,\n",
    "                \"snr_detrend\": snr,\n",
    "                \"f_vol\": fv,\n",
    "                \"hs4_leader\": hs4_lead,\n",
    "                \"hs4_follower\": hs4_foll,\n",
    "                \"hs4_equal\": int(hs4_lead == hs4_foll),\n",
    "                \"hs4_prefix2_equal\": int(str(hs4_lead)[:2] == str(hs4_foll)[:2]),\n",
    "                \"hs4_dist\": abs(int(hs4_lead) - int(hs4_foll)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    eda_df = pd.DataFrame(rows)\n",
    "    full = pd.concat([pairs_df.reset_index(drop=True), eda_df], axis=1)\n",
    "    print(f\"[EDA] pairs with EDA: {full.shape}\")\n",
    "    return full\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. 필터 스코어 함수\n",
    "# ============================================================\n",
    "def apply_filter(df: pd.DataFrame, params: Dict[str, float]) -> pd.DataFrame:\n",
    "    cond = (\n",
    "        (df[\"max_corr\"].abs() >= params[\"corr_min\"]) &\n",
    "        (df[\"corr_range\"] <= params[\"range_max\"]) &\n",
    "        (df[\"rollcorr_std\"] <= params[\"roll_max\"]) &\n",
    "        (df[\"dtw_dist\"] <= params[\"dtw_max\"]) &\n",
    "        (df[\"f_vol\"] <= params[\"fvol_max\"]) &\n",
    "        (df[\"snr_detrend\"] >= params[\"snr_min\"])\n",
    "    )\n",
    "    return df.loc[cond].copy()\n",
    "\n",
    "\n",
    "def evaluate_filter(df: pd.DataFrame, params: Dict[str, float]) -> Tuple[float, float]:\n",
    "    filtered = apply_filter(df, params)\n",
    "    n = len(filtered)\n",
    "\n",
    "    if n == 0:\n",
    "        return -1e9, 0.0  # 최악\n",
    "\n",
    "    # 적당한 pair 수 유도 (대략 800~2000 사이 선호)\n",
    "    if n < 300:\n",
    "        count_penalty = 0.5\n",
    "    elif n > 2500:\n",
    "        count_penalty = 0.5\n",
    "    else:\n",
    "        count_penalty = 0.0\n",
    "\n",
    "    mean_abs_corr = filtered[\"max_corr\"].abs().mean()\n",
    "    mean_snr = filtered[\"snr_detrend\"].clip(lower=0).mean()\n",
    "\n",
    "    # 기본 스코어\n",
    "    base = 0.6 * mean_abs_corr + 0.3 * mean_snr\n",
    "\n",
    "    # pair 수 비율\n",
    "    count_factor = np.clip(n / 1500.0, 0.3, 2.0)\n",
    "\n",
    "    score = base * count_factor - count_penalty\n",
    "    return float(score), float(n)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Random Search (trial 수 늘린 버전)\n",
    "# ============================================================\n",
    "def random_search_filters(df: pd.DataFrame,\n",
    "                          n_trials: int = 300,\n",
    "                          random_state: int = 42):\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    logs = []\n",
    "\n",
    "    # 탐색 범위 (EDA보고 잡은 heuristic)\n",
    "    for t in range(n_trials):\n",
    "        params = {\n",
    "            \"corr_min\": rng.uniform(0.25, 0.45),\n",
    "            \"range_max\": rng.uniform(0.25, 0.9),\n",
    "            \"roll_max\": rng.uniform(0.30, 0.65),\n",
    "            \"dtw_max\": rng.uniform(5e8, 2.5e9),\n",
    "            \"fvol_max\": rng.uniform(3e6, 1.5e7),\n",
    "            \"snr_min\": rng.uniform(0.03, 0.25),\n",
    "        }\n",
    "\n",
    "        score, n = evaluate_filter(df, params)\n",
    "        logs.append({**params, \"pair_count\": n, \"score\": score})\n",
    "\n",
    "    log_df = pd.DataFrame(logs)\n",
    "    best_idx = log_df[\"score\"].idxmax()\n",
    "    best_params = log_df.loc[best_idx].to_dict()\n",
    "\n",
    "    print(f\"\\n[RandomSearch] Best trial:\")\n",
    "    print(best_params)\n",
    "\n",
    "    # 로그 저장\n",
    "    log_df.to_csv(RS_LOG_PATH, index=False)\n",
    "    print(f\"Random search log saved → {RS_LOG_PATH}\")\n",
    "\n",
    "    # score, pair_count 제거하고 파라미터만 반환\n",
    "    for k in [\"score\", \"pair_count\"]:\n",
    "        best_params.pop(k, None)\n",
    "\n",
    "    return best_params, log_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Bayesian Optimization (옵션: skopt)\n",
    "# ============================================================\n",
    "def bayes_optimize_filters(df: pd.DataFrame,\n",
    "                           init_params: Dict[str, float],\n",
    "                           n_calls: int = 70):\n",
    "\n",
    "    if not SKOPT_AVAILABLE:\n",
    "        raise RuntimeError(\"skopt 미설치\")\n",
    "\n",
    "    # search space 정의\n",
    "    space = [\n",
    "        Real(0.25, 0.45, name=\"corr_min\"),\n",
    "        Real(0.25, 0.9,  name=\"range_max\"),\n",
    "        Real(0.30, 0.65, name=\"roll_max\"),\n",
    "        Real(5e8, 2.5e9, name=\"dtw_max\"),\n",
    "        Real(3e6, 1.5e7, name=\"fvol_max\"),\n",
    "        Real(0.03, 0.25, name=\"snr_min\"),\n",
    "    ]\n",
    "\n",
    "    def objective(x):\n",
    "        params = {\n",
    "            \"corr_min\": x[0],\n",
    "            \"range_max\": x[1],\n",
    "            \"roll_max\": x[2],\n",
    "            \"dtw_max\": x[3],\n",
    "            \"fvol_max\": x[4],\n",
    "            \"snr_min\": x[5],\n",
    "        }\n",
    "        score, _ = evaluate_filter(df, params)\n",
    "        return -score  # gp_minimize는 최소화 → 마이너스\n",
    "\n",
    "    # 초기점: random search best\n",
    "    x0 = [\n",
    "        init_params[\"corr_min\"],\n",
    "        init_params[\"range_max\"],\n",
    "        init_params[\"roll_max\"],\n",
    "        init_params[\"dtw_max\"],\n",
    "        init_params[\"fvol_max\"],\n",
    "        init_params[\"snr_min\"],\n",
    "    ]\n",
    "\n",
    "    res = gp_minimize(\n",
    "        objective,\n",
    "        space,\n",
    "        x0=[x0],\n",
    "        y0=[objective(x0)],\n",
    "        n_calls=n_calls,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    bo_best = {\n",
    "        \"corr_min\": res.x[0],\n",
    "        \"range_max\": res.x[1],\n",
    "        \"roll_max\": res.x[2],\n",
    "        \"dtw_max\": res.x[3],\n",
    "        \"fvol_max\": res.x[4],\n",
    "        \"snr_min\": res.x[5],\n",
    "    }\n",
    "\n",
    "    score, n = evaluate_filter(df, bo_best)\n",
    "    print(\"\\n[BayesOpt] Best params:\")\n",
    "    print(bo_best)\n",
    "    print(f\"[BayesOpt] score={score:.6f}, pair_count={n}\")\n",
    "\n",
    "    return bo_best, res\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. main\n",
    "# ============================================================\n",
    "def main():\n",
    "    # raw / pivot\n",
    "    train_raw = pd.read_csv(RAW_PATH)\n",
    "    _, _, pivot = build_train_month_and_pivot(RAW_PATH)\n",
    "\n",
    "    # base pairs\n",
    "    base_pairs = mine_all_pairs(pivot)\n",
    "\n",
    "    # EDA features\n",
    "    full_pairs = attach_eda_features(base_pairs, pivot, train_raw)\n",
    "\n",
    "    print(\"=== Random Search for filters ===\")\n",
    "    rs_best, _ = random_search_filters(full_pairs, n_trials=80, random_state=42)\n",
    "\n",
    "    # Bayesian Optimization (옵션)\n",
    "    if SKOPT_AVAILABLE:\n",
    "        print(\"\\n=== Bayesian Optimization for filters ===\")\n",
    "        final_params, _ = bayes_optimize_filters(full_pairs, init_params=rs_best, n_calls=30)\n",
    "    else:\n",
    "        print(\"\\n[INFO] skopt 없음 → Random Search 결과만 사용\")\n",
    "        final_params = rs_best\n",
    "\n",
    "    print(\"\\n[FINAL PARAMS]\")\n",
    "    print(final_params)\n",
    "\n",
    "    # 최종 필터 적용\n",
    "    best_pairs = apply_filter(full_pairs, final_params).reset_index(drop=True)\n",
    "    print(f\"[FINAL] filtered pairs: {len(best_pairs)}\")\n",
    "\n",
    "    # 저장\n",
    "    best_pairs.to_csv(BEST_PAIR_PATH, index=False)\n",
    "    print(f\"[SAVE] pairs_v10_best.csv → {BEST_PAIR_PATH} (rows={len(best_pairs)})\")\n",
    "    print(\"✅ DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1982ad9-be68-42e4-8ee0-eed4010dc6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
