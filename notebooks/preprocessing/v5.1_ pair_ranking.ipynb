{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8877d409-9621-4758-a084-3e8e6adc24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FE Notebook A ‚Äî Pair Ranking Pipeline\n",
    "1) pair_df ÏÉùÏÑ±\n",
    "2) score Í≥ÑÏÇ∞ + refine\n",
    "3) TOP N ÏÑ†ÌÉù\n",
    "4) leader-follower direction Í≤∞Ï†ï\n",
    "5) direction_df_topN.csv Ï†ÄÏû•\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.signal import correlate\n",
    "from fastdtw import fastdtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db9b501-4249-4e58-a7ff-cd48e3a337c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Building pair_df...\n",
      "pair_df shape: (4950, 19)\n",
      "üìå After refine: (4073, 24)\n",
      "[auto-N] q=0.990, thr=6.2989, pairs=41\n",
      "[auto-N] q=0.985, thr=6.0485, pairs=62\n",
      "[auto-N] q=0.980, thr=5.8315, pairs=82\n",
      "[auto-N] q=0.975, thr=5.6631, pairs=102\n",
      "[auto-N] q=0.970, thr=5.5361, pairs=123\n",
      "[auto-N] q=0.965, thr=5.4189, pairs=143\n",
      "[auto-N] q=0.960, thr=5.3494, pairs=163\n",
      "[auto-N] q=0.955, thr=5.2126, pairs=184\n",
      "[auto-N] q=0.950, thr=5.1511, pairs=204\n",
      "===================================\n",
      "[auto-N] ÏµúÏ¢Ö ÏÑ†ÌÉù: q=0.950, N=204\n",
      "score_v1 Î≤îÏúÑ: 5.153577862711564 ~ 8.316253836905712\n",
      "===================================\n",
      "üéâ Saved:\n",
      " - pair_df_v1.csv\n",
      " - direction_df_autoN.csv\n",
      "ÏµúÏ¢Ö ÏÑ†ÌÉùÎêú pair Ïàò: 204\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Utility Ìï®ÏàòÎì§\n",
    "# =========================================================\n",
    "\n",
    "def safe_cosine(a, b):\n",
    "    if np.all(a == 0) or np.all(b == 0):\n",
    "        return 0.0\n",
    "    return 1 - cosine(a, b)\n",
    "\n",
    "\n",
    "def compute_cross_corr(x, y):\n",
    "    x = (x - x.mean()) / (x.std() + 1e-9)\n",
    "    y = (y - y.mean()) / (y.std() + 1e-9)\n",
    "    c = correlate(x, y, mode=\"full\")\n",
    "    lag = c.argmax() - (len(x) - 1)\n",
    "    return c.max(), lag\n",
    "\n",
    "\n",
    "def compute_sign_agree(x, y):\n",
    "    sx = np.sign(np.diff(x))\n",
    "    sy = np.sign(np.diff(y))\n",
    "    return (sx == sy).mean()\n",
    "\n",
    "\n",
    "def compute_dtw(a, b):\n",
    "    dist, _ = fastdtw(a, b)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def hs_distance(h1, h2):\n",
    "    if h1 == h2: return 0\n",
    "    if h1[:3] == h2[:3]: return 1\n",
    "    if h1[:2] == h2[:2]: return 2\n",
    "    return 3\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) pair_df ÏÉùÏÑ±\n",
    "# =========================================================\n",
    "\n",
    "def build_pair_df(monthly):\n",
    "\n",
    "    monthly = monthly.copy()\n",
    "    monthly[\"t\"] = (monthly[\"year\"] - monthly[\"year\"].min()) * 12 + monthly[\"month\"]\n",
    "\n",
    "    monthly_agg = monthly.groupby([\"item_id\", \"t\"], as_index=False).agg(\n",
    "        total_value=(\"total_value\", \"sum\"),\n",
    "        total_weight=(\"total_weight\", \"sum\")\n",
    "    )\n",
    "\n",
    "    ts_val = monthly_agg.pivot(index=\"item_id\", columns=\"t\", values=\"total_value\").fillna(0)\n",
    "    ts_wgt = monthly_agg.pivot(index=\"item_id\", columns=\"t\", values=\"total_weight\").fillna(0)\n",
    "\n",
    "    items = ts_val.index.tolist()\n",
    "\n",
    "    meta = monthly.drop_duplicates(\"item_id\").copy()\n",
    "    meta[\"hs4\"] = meta[\"hs4\"].astype(str).str.zfill(4)\n",
    "    meta[\"hs3\"] = meta[\"hs3\"].astype(str)\n",
    "    meta[\"hs2\"] = meta[\"hs2\"].astype(str)\n",
    "    meta = meta.set_index(\"item_id\")\n",
    "\n",
    "    pair_list = []\n",
    "\n",
    "    for item_i, item_j in combinations(items, 2):\n",
    "        v_i, v_j = ts_val.loc[item_i].values, ts_val.loc[item_j].values\n",
    "        w_i, w_j = ts_wgt.loc[item_i].values, ts_wgt.loc[item_j].values\n",
    "\n",
    "        cos_val = safe_cosine(v_i, v_j)\n",
    "        cos_wgt = safe_cosine(w_i, w_j)\n",
    "        cc_val, lag_val = compute_cross_corr(v_i, v_j)\n",
    "        sign_agree = compute_sign_agree(v_i, v_j)\n",
    "        dtw_dist = compute_dtw(v_i, v_j)\n",
    "        dtw_sim = 1 / (1 + dtw_dist)\n",
    "        hs_dist = hs_distance(meta.loc[item_i, \"hs4\"], meta.loc[item_j, \"hs4\"])\n",
    "        same_cluster = int(meta.loc[item_i, \"cluster_wv\"] == meta.loc[item_j, \"cluster_wv\"])\n",
    "\n",
    "        pair_list.append([\n",
    "            item_i, item_j,\n",
    "            cos_val, cos_wgt, sign_agree,\n",
    "            cc_val, lag_val,\n",
    "            dtw_dist, dtw_sim,\n",
    "            hs_dist,\n",
    "            meta.loc[item_i, \"hs4\"], meta.loc[item_j, \"hs4\"],\n",
    "            meta.loc[item_i, \"hs3\"], meta.loc[item_j, \"hs3\"],\n",
    "            meta.loc[item_i, \"hs2\"], meta.loc[item_j, \"hs2\"],\n",
    "            meta.loc[item_i, \"cluster_wv\"], meta.loc[item_j, \"cluster_wv\"],\n",
    "            same_cluster\n",
    "        ])\n",
    "\n",
    "    cols = [\n",
    "        \"item_i\", \"item_j\",\n",
    "        \"cos_val\", \"cos_wgt\", \"sign_agree_val\",\n",
    "        \"cc_val\", \"lag_val\",\n",
    "        \"dtw_dist\", \"dtw_sim\",\n",
    "        \"hs_dist\",\n",
    "        \"hs4_i\", \"hs4_j\",\n",
    "        \"hs3_i\", \"hs3_j\",\n",
    "        \"hs2_i\", \"hs2_j\",\n",
    "        \"cluster_i\", \"cluster_j\",\n",
    "        \"same_cluster\"\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(pair_list, columns=cols)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Normalize + score + refine\n",
    "# =========================================================\n",
    "\n",
    "def normalize_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"dtw_norm\"] = (df[\"dtw_dist\"] - df[\"dtw_dist\"].min()) / (df[\"dtw_dist\"].max() - df[\"dtw_dist\"].min() + 1e-9)\n",
    "    df[\"hs_dist_norm\"] = df[\"hs_dist\"].astype(float)\n",
    "    df[\"cluster_sim\"] = df[\"same_cluster\"].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_lag_direction_score(lag):\n",
    "    if lag in [1, 2]: return 1.0\n",
    "    if lag == 0: return 0.0\n",
    "    if lag < 0: return -1.0\n",
    "    return 0.5\n",
    "\n",
    "\n",
    "def compute_pair_score_v1(df):\n",
    "    df = df.copy()\n",
    "    df[\"lag_dir\"] = df[\"lag_val\"].apply(compute_lag_direction_score)\n",
    "    df[\"score_v1\"] = (\n",
    "          0.30 * df[\"cos_val\"]\n",
    "        + 0.10 * df[\"cos_wgt\"]\n",
    "        + 0.20 * df[\"cc_val\"]\n",
    "        + 0.15 * df[\"sign_agree_val\"]\n",
    "        - 0.10 * df[\"dtw_norm\"]\n",
    "        - 0.10 * df[\"hs_dist_norm\"]\n",
    "        + 0.05 * df[\"cluster_sim\"]\n",
    "        + 0.10 * df[\"lag_dir\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def refine_pairs(df):\n",
    "    df = df.copy()\n",
    "    # 1Ï∞® Í±∞Î•∏ ÌïÑÌÑ∞ (ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞Ïö©)\n",
    "    df = df[df[\"cos_val\"] > -0.05]\n",
    "    df = df[df[\"sign_agree_val\"] >= 0.30]\n",
    "\n",
    "    # cc_val Ïä§ÌååÏù¥ÌÅ¨ + cos_val ÎÇÆÏùÄ Í≤ΩÏö∞ Ï†úÍ±∞ (Í∏âÎì±/Í∏âÎùΩ Ìïú Î≤àÎßå ÎßûÏùÄ Í≤É)\n",
    "    spike_mask = (df[\"cc_val\"] > df[\"cc_val\"].quantile(0.98)) & (df[\"cos_val\"] < 0.05)\n",
    "    df = df[~spike_mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2-1) TOP_N ÏûêÎèô ÏÑ†ÌÉù (ÌïµÏã¨)\n",
    "# =========================================================\n",
    "\n",
    "def auto_select_top_pairs(df,\n",
    "                          min_pairs=200,\n",
    "                          max_pairs=1500,\n",
    "                          fallback_top=500):\n",
    "    \"\"\"\n",
    "    score_v1 Í∏∞Ï§ÄÏúºÎ°ú ÏÉÅÏúÑ Íµ¨Í∞ÑÏóêÏÑú ÏûêÎèôÏúºÎ°ú N Í≤∞Ï†ï.\n",
    "    - Ïö∞ÏÑ† high-quantile(0.99 ~ 0.90) Íµ¨Í∞ÑÏóêÏÑú\n",
    "      min_pairs ~ max_pairs ÏÇ¨Ïù¥Í∞Ä ÎêòÎèÑÎ°ù threshold ÏÑ†ÌÉù\n",
    "    - Î™ª Ï∞æÏúºÎ©¥ fallback_topÍ∞ú ÏÇ¨Ïö©\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # score_v1 high ‚Üí Ï¢ãÏùå\n",
    "    scores = df[\"score_v1\"]\n",
    "    quantiles = [0.99, 0.985, 0.98, 0.975, 0.97,\n",
    "                 0.965, 0.96, 0.955, 0.95, 0.94, 0.93, 0.92, 0.90]\n",
    "\n",
    "    chosen = None\n",
    "    chosen_q = None\n",
    "\n",
    "    for q in quantiles:\n",
    "        thr = scores.quantile(q)\n",
    "        cand = df[df[\"score_v1\"] >= thr]\n",
    "        n = len(cand)\n",
    "        print(f\"[auto-N] q={q:.3f}, thr={thr:.4f}, pairs={n}\")\n",
    "        if min_pairs <= n <= max_pairs:\n",
    "            chosen = cand\n",
    "            chosen_q = q\n",
    "            break\n",
    "\n",
    "    if chosen is None:\n",
    "        # fallback: Îã®ÏàúÌûà ÏÉÅÏúÑ fallback_topÍ∞ú\n",
    "        chosen = df.sort_values(\"score_v1\", ascending=False).head(fallback_top)\n",
    "        chosen_q = None\n",
    "        print(f\"[auto-N] Ï†ÅÎãπÌïú qÎ•º Î™ª Ï∞æÏïÑÏÑú ÏÉÅÏúÑ {fallback_top}Í∞ú ÏÇ¨Ïö©\")\n",
    "\n",
    "    chosen = chosen.sort_values(\"score_v1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"===================================\")\n",
    "    if chosen_q is not None:\n",
    "        print(f\"[auto-N] ÏµúÏ¢Ö ÏÑ†ÌÉù: q={chosen_q:.3f}, N={len(chosen)}\")\n",
    "    else:\n",
    "        print(f\"[auto-N] ÏµúÏ¢Ö ÏÑ†ÌÉù: fallback, N={len(chosen)}\")\n",
    "    print(\"score_v1 Î≤îÏúÑ:\", chosen[\"score_v1\"].min(), \"~\", chosen[\"score_v1\"].max())\n",
    "    print(\"===================================\")\n",
    "\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) Direction Í≤∞Ï†ï\n",
    "# =========================================================\n",
    "\n",
    "def compute_trend_slope(ts):\n",
    "    x = np.arange(len(ts))\n",
    "    if np.std(ts) < 1e-9:\n",
    "        return 0.0\n",
    "    return np.polyfit(x, ts, 1)[0]\n",
    "\n",
    "\n",
    "def recent_growth(ts, w=6):\n",
    "    if len(ts) < w+1: return 0.0\n",
    "    return ts[-1] - ts[-w]\n",
    "\n",
    "\n",
    "def determine_direction(row, ts_val):\n",
    "\n",
    "    i, j = row[\"item_i\"], row[\"item_j\"]\n",
    "    lag = row[\"lag_val\"]\n",
    "    v_i = ts_val.loc[i].values\n",
    "    v_j = ts_val.loc[j].values\n",
    "\n",
    "    # 1) lag Í∏∞Î∞ò: ÏñëÏàòÎ©¥ i‚Üíj, ÏùåÏàòÎ©¥ j‚Üíi\n",
    "    if lag > 0: return i, j\n",
    "    if lag < 0: return j, i\n",
    "\n",
    "    # 2) lag==0Ïùº Îïå Î≥¥Ï°∞ Í∏∞Ï§Ä\n",
    "\n",
    "    # (1) ÏµúÍ∑º 6Í∞úÏõî growth\n",
    "    g_i, g_j = recent_growth(v_i), recent_growth(v_j)\n",
    "    if g_i != g_j:\n",
    "        return (i, j) if g_i > g_j else (j, i)\n",
    "\n",
    "    # (2) Ï†ÑÍ∏∞Í∞Ñ Í∏∞Ïö∏Í∏∞\n",
    "    s_i, s_j = compute_trend_slope(v_i), compute_trend_slope(v_j)\n",
    "    if s_i != s_j:\n",
    "        return (i, j) if s_i > s_j else (j, i)\n",
    "\n",
    "    # (3) ÎßàÏßÄÎßâ Í∞í(Í∑úÎ™®)\n",
    "    return (i, j) if v_i[-1] > v_j[-1] else (j, i)\n",
    "\n",
    "\n",
    "def assign_directions(top_pairs, monthly):\n",
    "\n",
    "    monthly = monthly.copy()\n",
    "    monthly[\"t\"] = (monthly[\"year\"] - monthly[\"year\"].min())*12 + monthly[\"month\"]\n",
    "\n",
    "    monthly = monthly.groupby([\"item_id\", \"t\"], as_index=False).agg(\n",
    "        total_value=(\"total_value\", \"sum\")\n",
    "    )\n",
    "    ts_val = monthly.pivot(index=\"item_id\", columns=\"t\", values=\"total_value\").fillna(0)\n",
    "\n",
    "    leaders, followers = [], []\n",
    "\n",
    "    for _, row in top_pairs.iterrows():\n",
    "        L, F = determine_direction(row, ts_val)\n",
    "        leaders.append(L)\n",
    "        followers.append(F)\n",
    "\n",
    "    out = top_pairs.copy()\n",
    "    out[\"leader\"] = leaders\n",
    "    out[\"follower\"] = followers\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Ïã§Ìñâ\n",
    "# =========================================================\n",
    "\n",
    "monthly = pd.read_csv(\"/data/ephemeral/home/data/processed/train_monthly_v2.csv\")\n",
    "\n",
    "print(\"üìå Building pair_df...\")\n",
    "pair_df = build_pair_df(monthly)\n",
    "print(\"pair_df shape:\", pair_df.shape)\n",
    "\n",
    "pair_df = normalize_features(pair_df)\n",
    "pair_df = compute_pair_score_v1(pair_df)\n",
    "pair_df = refine_pairs(pair_df)\n",
    "\n",
    "print(\"üìå After refine:\", pair_df.shape)\n",
    "\n",
    "# üî• Ïó¨Í∏∞ÏÑú N ÏûêÎèô Í≤∞Ï†ï\n",
    "top_pairs = auto_select_top_pairs(\n",
    "    pair_df,\n",
    "    min_pairs=200,\n",
    "    max_pairs=600,\n",
    "    fallback_top=500\n",
    ")\n",
    "\n",
    "direction_df = assign_directions(top_pairs, monthly)\n",
    "\n",
    "pair_df.to_csv(\"pair_df_v1.csv\", index=False)\n",
    "direction_df.to_csv(\"direction_df_autoN.csv\", index=False)\n",
    "\n",
    "print(\"üéâ Saved:\")\n",
    "print(\" - pair_df_v1.csv\")\n",
    "print(\" - direction_df_autoN.csv\")\n",
    "print(\"ÏµúÏ¢Ö ÏÑ†ÌÉùÎêú pair Ïàò:\", len(direction_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc6b90-a4c4-4457-9a1d-28c642c01bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bcdfd-1521-4d06-a348-8f28d3786679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
