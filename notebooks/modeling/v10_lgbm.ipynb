{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902dc4be-5056-472f-ac3c-e70ff9efa1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Load monthly & pivot ===\n",
      "=== Load best pairs ===\n",
      "[INFO] pairs: 1513\n",
      "=== Build training df ===\n",
      "[INFO] training rows: 52721\n",
      "=== Train LGBM seed ensemble ===\n",
      "[Seed 42] RMSE = 2.27621\n",
      "[Seed 43] RMSE = 2.26147\n",
      "[Seed 44] RMSE = 2.27165\n",
      "Avg RMSE: 2.269775444343751\n",
      "=== Build inference features ===\n",
      "[INFO] pred_df rows: 1513\n",
      "=== Create submission ===\n",
      "[INFO] submission rows: 1513\n",
      "[SAVE] /data/ephemeral/home/data/processed/v10_model_output/submission_v10_lgbm_seed.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# modeling_v10_lgbm_seed.py\n",
    "# - pair 기반 LightGBM 회귀 (단일 LGBM + seed 앙상블)\n",
    "# - sample_submission 사용 X → 우리가 찾은 pair만 제출\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. PATH 설정\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parents[1] / \"data\"\n",
    "\n",
    "TRAIN_MONTH_PATH = DATA_DIR / \"processed\" / \"train_month.csv\"\n",
    "PAIRS_PATH       = DATA_DIR / \"processed\" / \"v10_pairs\" / \"pairs_v10_best.csv\"\n",
    "\n",
    "OUTPUT_DIR       = DATA_DIR / \"processed\" / \"v10_model_output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. train_month → pivot 생성\n",
    "# ============================================================\n",
    "def load_monthly_data():\n",
    "    df = pd.read_csv(TRAIN_MONTH_PATH)\n",
    "    df[\"ym\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-\" +\n",
    "                              df[\"month\"].astype(str) + \"-01\")\n",
    "\n",
    "    pivot = (\n",
    "        df.pivot_table(index=\"ym\", columns=\"item_id\", values=\"value\", aggfunc=\"sum\")\n",
    "          .sort_index()\n",
    "          .fillna(0.0)\n",
    "    )\n",
    "    return df, pivot\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. single-pair 시계열 피처 생성\n",
    "# ============================================================\n",
    "def build_pair_frame(pivot, leader, follower, lag, corr):\n",
    "    a = pivot[leader]\n",
    "    b = pivot[follower]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pivot.index,\n",
    "        \"b_t\": b.values,\n",
    "        \"b_t_1\": b.shift(1).values,\n",
    "        \"b_t_2\": b.shift(2).values,\n",
    "        \"a_t_lag\": a.shift(lag).values,\n",
    "        \"a_t_lag_1\": a.shift(lag + 1).values,\n",
    "    })\n",
    "\n",
    "    df[\"b_diff1\"] = df[\"b_t\"] - df[\"b_t_1\"]\n",
    "    df[\"b_pct1\"] = (df[\"b_diff1\"]) / (df[\"b_t_1\"].replace(0, np.nan) + 1e-6)\n",
    "\n",
    "    df[\"target_value\"] = b.shift(-1).values\n",
    "    df[\"target_log\"] = np.log1p(df[\"target_value\"].clip(lower=0))\n",
    "    df[\"target_date\"] = df[\"date\"] + pd.offsets.MonthBegin(1)\n",
    "\n",
    "    df[\"leading_item_id\"] = leader\n",
    "    df[\"following_item_id\"] = follower\n",
    "    df[\"lag_val\"] = lag\n",
    "    df[\"corr\"] = corr\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_training_data(pivot, pairs_df):\n",
    "    frames = []\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        f = build_pair_frame(\n",
    "            pivot,\n",
    "            row[\"leading_item_id\"],\n",
    "            row[\"following_item_id\"],\n",
    "            row[\"best_lag\"],\n",
    "            row[\"max_corr\"],\n",
    "        )\n",
    "        if len(f) > 12:\n",
    "            frames.append(f)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"훈련 데이터 없음.\")\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LGBM 단일 모델 + SEED ensemble\n",
    "# ============================================================\n",
    "def train_single_lgbm(X_train, y_train, X_valid, y_valid, seed):\n",
    "    model = LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        n_estimators=1400,\n",
    "        learning_rate=0.045,\n",
    "        num_leaves=80,\n",
    "        max_depth=-1,\n",
    "        min_child_samples=30,\n",
    "        subsample=0.8,\n",
    "        subsample_freq=2,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_lambda=3.0,\n",
    "        reg_alpha=1.0,\n",
    "        random_state=seed,\n",
    "        verbosity=-1,\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric=\"l2\",\n",
    "    )\n",
    "\n",
    "    pred = model.predict(X_valid)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, pred))\n",
    "    return model, rmse\n",
    "\n",
    "\n",
    "def train_lgbm_seed_ensemble(train_df, seeds=[42, 43, 44]):\n",
    "    exclude = [\n",
    "        \"target_value\", \"target_log\",\n",
    "        \"date\", \"target_date\",\n",
    "        \"leading_item_id\", \"following_item_id\"\n",
    "    ]\n",
    "    feature_cols = [c for c in train_df.columns if c not in exclude]\n",
    "\n",
    "    train_cutoff = pd.Timestamp(\"2024-12-01\")\n",
    "    valid_start  = pd.Timestamp(\"2025-01-01\")\n",
    "    valid_end    = pd.Timestamp(\"2025-05-01\")\n",
    "\n",
    "    train_mask = train_df[\"target_date\"] <= train_cutoff\n",
    "    valid_mask = (train_df[\"target_date\"] >= valid_start) & \\\n",
    "                 (train_df[\"target_date\"] <= valid_end)\n",
    "\n",
    "    X_train = train_df.loc[train_mask, feature_cols]\n",
    "    y_train = train_df.loc[train_mask, \"target_log\"]\n",
    "\n",
    "    X_valid = train_df.loc[valid_mask, feature_cols]\n",
    "    y_valid = train_df.loc[valid_mask, \"target_log\"]\n",
    "\n",
    "    models, rmses = [], []\n",
    "\n",
    "    for seed in seeds:\n",
    "        model, rmse = train_single_lgbm(X_train, y_train, X_valid, y_valid, seed)\n",
    "        print(f\"[Seed {seed}] RMSE = {rmse:.5f}\")\n",
    "        models.append(model)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    print(\"Avg RMSE:\", np.mean(rmses))\n",
    "    return models, feature_cols\n",
    "\n",
    "\n",
    "def predict_ensemble(models, X):\n",
    "    preds = [m.predict(X) for m in models]\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. inference: 마지막 row를 feature 로 사용\n",
    "# ============================================================\n",
    "def build_inference_features(pivot, pairs_df):\n",
    "    rows = []\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        df = build_pair_frame(\n",
    "            pivot,\n",
    "            row[\"leading_item_id\"],\n",
    "            row[\"following_item_id\"],\n",
    "            row[\"best_lag\"],\n",
    "            row[\"max_corr\"],\n",
    "        )\n",
    "        if df.empty:\n",
    "            continue\n",
    "        rows.append(df.iloc[-1].copy())\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. 제출 생성 (우리가 찾은 pair만)\n",
    "# ============================================================\n",
    "def create_submission(pairs_df, pred_df, models, feature_cols):\n",
    "    if pred_df.empty:\n",
    "        raise ValueError(\"pred_df 비어 있음.\")\n",
    "\n",
    "    sub = pairs_df[[\"leading_item_id\", \"following_item_id\"]].copy()\n",
    "\n",
    "    sub = sub.merge(\n",
    "        pred_df[[\"leading_item_id\", \"following_item_id\"] + feature_cols],\n",
    "        on=[\"leading_item_id\", \"following_item_id\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    X_test = sub[feature_cols].fillna(0.0)\n",
    "    y_pred = np.expm1(predict_ensemble(models, X_test))\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "\n",
    "    sub[\"value\"] = y_pred.round().astype(int)\n",
    "\n",
    "    print(f\"[INFO] submission rows: {len(sub)}\")\n",
    "    return sub[[\"leading_item_id\", \"following_item_id\", \"value\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. MAIN\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"=== Load monthly & pivot ===\")\n",
    "    _, pivot = load_monthly_data()\n",
    "\n",
    "    print(\"=== Load best pairs ===\")\n",
    "    pairs_df = pd.read_csv(PAIRS_PATH)\n",
    "    print(f\"[INFO] pairs: {len(pairs_df)}\")\n",
    "\n",
    "    print(\"=== Build training df ===\")\n",
    "    train_df = build_training_data(pivot, pairs_df)\n",
    "    print(f\"[INFO] training rows: {len(train_df)}\")\n",
    "\n",
    "    print(\"=== Train LGBM seed ensemble ===\")\n",
    "    models, feature_cols = train_lgbm_seed_ensemble(train_df)\n",
    "\n",
    "    print(\"=== Build inference features ===\")\n",
    "    pred_df = build_inference_features(pivot, pairs_df)\n",
    "    print(f\"[INFO] pred_df rows: {len(pred_df)}\")\n",
    "\n",
    "    print(\"=== Create submission ===\")\n",
    "    submission = create_submission(pairs_df, pred_df, models, feature_cols)\n",
    "\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    out_path = OUTPUT_DIR / \"submission_v10_lgbm_seed.csv\"\n",
    "    submission.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d019ae-e3ac-4c64-bfcd-a712f361336f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb20a48-761c-4194-9c4a-be16693dbd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
