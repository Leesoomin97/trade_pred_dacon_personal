{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0730021f-cb9a-4c89-b65a-6d7c6841b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [1] Load monthly & pivot ===\n",
      "=== [2] Load pairs_v10_best (BayesOpt í•„í„° ë°˜ì˜ë³¸) ===\n",
      "[INFO] pairs_v10_best rows: 2234\n",
      "=== [3] Build training df (hybrid FE) ===\n",
      "[INFO] training rows: 83841\n",
      "=== [4] Train LGBM seed ensemble (MAE objective) ===\n",
      "[Split] Train: (68203, 23), Valid: (11170, 23)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5125\n",
      "[LightGBM] [Info] Number of data points in the train set: 68203, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 12.939315\n",
      "[Seed 42] Valid MAE (log1p-space) = 1.03837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5125\n",
      "[LightGBM] [Info] Number of data points in the train set: 68203, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 12.939315\n",
      "[Seed 2024] Valid MAE (log1p-space) = 1.01079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5125\n",
      "[LightGBM] [Info] Number of data points in the train set: 68203, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 12.939315\n",
      "[Seed 777] Valid MAE (log1p-space) = 1.03950\n",
      "[Ensemble] Avg MAE (log1p-space) = 1.02956\n",
      "=== [5] Build inference features for 2025-08 ===\n",
      "[INFO] pred_df rows: 2234\n",
      "=== [6] Create submission (value >= 1000 only) ===\n",
      "[INFO] raw submission rows: 2234\n",
      "[INFO] filtered submission rows (value >= 1000): 2092\n",
      "[SAVE] /root/import-predict/data/processed/v13_model_output/submission_v13_lgbm_hybrid_valge1000.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# modeling_v13_lgbm_hybrid.py\n",
    "# - v10 pairs (BayesOpt í•„í„° ë°˜ì˜ëœ pairs_v10_best.csv) ì‚¬ìš©\n",
    "# - ì¶”ê°€ EDA í•„í„°ë§ ì—†ìŒ (ì „ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ìµœì  í•„í„° ì ìš©)\n",
    "# - train_month(Bì•ˆ) ê¸°ë°˜ pivot â†’ pairë³„ ì‹œê³„ì—´ feature\n",
    "# - íŒ€ì› ì½”ë“œì˜ leader alignment + rich FE + MAE objective\n",
    "# - ìš°ë¦¬ ìª½ seed ensemble êµ¬ì¡° ê²°í•©\n",
    "# - sample_submission ë¯¸ì‚¬ìš©: ìš°ë¦¬ê°€ ì°¾ì€ pairë§Œ ì˜ˆì¸¡\n",
    "# - value >= 1000 ì¸ pairë§Œ ìµœì¢… ì œì¶œ\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. PATH ì„¤ì •\n",
    "# ============================================================\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "DATA_DIR = BASE_DIR.parents[1] / \"data\"\n",
    "\n",
    "TRAIN_MONTH_PATH = DATA_DIR / \"processed\" / \"train_month.csv\"          # Bì•ˆ ê²°ê³¼\n",
    "PAIRS_PATH       = DATA_DIR / \"processed\" / \"v10_pairs\" / \"pairs_v10_best.csv\"\n",
    "\n",
    "OUTPUT_DIR       = DATA_DIR / \"processed\" / \"v13_model_output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. train_month â†’ pivot ìƒì„±\n",
    "#    (ì „ì²˜ë¦¬ì—ì„œ ë§Œë“  train_month.csv ê¸°ë°˜, hs4 í¬í•¨)\n",
    "# ============================================================\n",
    "def load_monthly_data():\n",
    "    df = pd.read_csv(TRAIN_MONTH_PATH)\n",
    "\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "\n",
    "    df[\"ym\"] = pd.to_datetime(\n",
    "        df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str) + \"-01\"\n",
    "    )\n",
    "\n",
    "    # item_id Ã— ym pivot (value í•©ê³„)\n",
    "    pivot = (\n",
    "        df.pivot_table(\n",
    "            index=\"ym\",\n",
    "            columns=\"item_id\",\n",
    "            values=\"value\",\n",
    "            aggfunc=\"sum\",\n",
    "        )\n",
    "        .sort_index()\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    return df, pivot\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. pair ë‹¨ìœ„ feature frame ìƒì„± (íŒ€ì› alignment + ìš°ë¦¬ êµ¬ì¡°)\n",
    "# ============================================================\n",
    "def _build_pair_frame(\n",
    "    pivot: pd.DataFrame,\n",
    "    leader: str,\n",
    "    follower: str,\n",
    "    best_lag: int,\n",
    "    max_corr: float,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - follower(b_t)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ rich time-series feature ìƒì„±\n",
    "    - leaderëŠ” best_lagì„ ê³ ë ¤í•œ 'aligned' íƒ€ì´ë°ìœ¼ë¡œ ì •ë ¬\n",
    "    - target: follower(t+1) ì˜ log1p(value)\n",
    "    \"\"\"\n",
    "\n",
    "    a_raw = pivot[leader]      # leader at t\n",
    "    b_t   = pivot[follower]    # follower at t\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": pivot.index,\n",
    "            \"b_t\": b_t.values,\n",
    "            \"a_raw\": a_raw.values,   # ì°¸ê³ ìš© (featureì—ì„œëŠ” ì œì™¸ ì˜ˆì •)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Follower features\n",
    "    # -----------------------------\n",
    "    df[\"b_t_1\"] = df[\"b_t\"].shift(1)\n",
    "    df[\"b_t_2\"] = df[\"b_t\"].shift(2)\n",
    "\n",
    "    df[\"b_diff1\"] = df[\"b_t\"] - df[\"b_t_1\"]\n",
    "    df[\"b_diff2\"] = df[\"b_t\"] - df[\"b_t_2\"]\n",
    "\n",
    "    df[\"b_pct1\"] = df[\"b_diff1\"] / (df[\"b_t_1\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"b_pct2\"] = df[\"b_diff2\"] / (df[\"b_t_2\"].replace(0, np.nan) + 1e-6)\n",
    "\n",
    "    df[\"b_roll3\"] = df[\"b_t\"].rolling(window=3, min_periods=1).mean()\n",
    "    df[\"b_std3\"] = df[\"b_t\"].rolling(window=3, min_periods=1).std()\n",
    "\n",
    "    df[\"b_expanding_mean\"] = df[\"b_t\"].expanding(min_periods=1).mean()\n",
    "    df[\"b_zscore3\"] = (df[\"b_t\"] - df[\"b_roll3\"]) / (df[\"b_std3\"] + 1e-6)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Leader alignment (í•µì‹¬)\n",
    "    # -----------------------------\n",
    "    # ì›ë˜ best_lag ì€ leader(t-lag) vs follower(t) ê¸°ì¤€ìœ¼ë¡œ ì°¾ìŒ.\n",
    "    # ìš°ë¦¬ê°€ ì˜ˆì¸¡í•˜ë ¤ëŠ” ê²ƒì€ follower(t+1).\n",
    "    # follower(t+1)ì— ëŒ€ì‘í•˜ëŠ” leader ì‹œì ì€ leader(t+1 - lag).\n",
    "    # row tì—ì„œ ì‚¬ìš©í•  leader ì •ë³´ëŠ” leader(t+1-lag) â†’ index ê¸°ì¤€ìœ¼ë¡œ shift_amount = lag-1\n",
    "    shift_amount = int(best_lag) - 1\n",
    "    df[\"a_t_aligned\"] = df[\"a_raw\"].shift(shift_amount)\n",
    "\n",
    "    df[\"a_t_aligned_1\"] = df[\"a_t_aligned\"].shift(1)\n",
    "    df[\"a_t_aligned_2\"] = df[\"a_t_aligned\"].shift(2)\n",
    "\n",
    "    df[\"a_diff1\"] = df[\"a_t_aligned\"] - df[\"a_t_aligned_1\"]\n",
    "    df[\"a_pct1\"] = df[\"a_diff1\"] / (df[\"a_t_aligned_1\"].replace(0, np.nan) + 1e-6)\n",
    "    df[\"a_roll3\"] = df[\"a_t_aligned\"].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Interaction features\n",
    "    # -----------------------------\n",
    "    df[\"ab_ratio\"] = df[\"a_t_aligned\"] / (df[\"b_t\"] + 1e-6)\n",
    "    df[\"ab_diff\"] = df[\"a_t_aligned\"] - df[\"b_t\"]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Seasonality-ish (month, quarter)\n",
    "    # -----------------------------\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "\n",
    "    # -----------------------------\n",
    "    # Target: follower(t+1)\n",
    "    # -----------------------------\n",
    "    df[\"target_value\"] = df[\"b_t\"].shift(-1)\n",
    "    df[\"target_log1p\"] = np.log1p(df[\"target_value\"].clip(lower=0))\n",
    "    df[\"target_date\"] = df[\"date\"] + pd.offsets.MonthBegin(1)\n",
    "\n",
    "    # Meta\n",
    "    df[\"leading_item_id\"] = leader\n",
    "    df[\"following_item_id\"] = follower\n",
    "    df[\"best_lag\"] = best_lag\n",
    "    df[\"max_corr\"] = max_corr\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_training_data(pivot: pd.DataFrame, pairs_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        pair_frame = _build_pair_frame(\n",
    "            pivot=pivot,\n",
    "            leader=row[\"leading_item_id\"],\n",
    "            follower=row[\"following_item_id\"],\n",
    "            best_lag=int(row[\"best_lag\"]),\n",
    "            max_corr=float(row[\"max_corr\"]),\n",
    "        )\n",
    "\n",
    "        # ìµœì†Œí•œì˜ history í™•ë³´ (b_t_2, a_t_aligned_2 ì¡´ì¬í•˜ëŠ” êµ¬ê°„ë§Œ)\n",
    "        pair_frame = pair_frame.dropna(subset=[\"b_t_2\", \"a_t_aligned_2\"])\n",
    "\n",
    "        # ë„ˆë¬´ ì§§ì€ ì‹œê³„ì—´ pairëŠ” ì œê±°\n",
    "        if len(pair_frame) <= 8:\n",
    "            continue\n",
    "\n",
    "        frames.append(pair_frame)\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"í›ˆë ¨ ë°ì´í„° ì—†ìŒ. (ëª¨ë“  pair frameì´ ë¹„ì—ˆìŒ)\")\n",
    "\n",
    "    train_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # target ì—†ëŠ” ë§ˆì§€ë§‰ êµ¬ê°„ ì œê±°\n",
    "    train_df = train_df[train_df[\"target_log1p\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LGBM seed ensemble (MAE objective)\n",
    "# ============================================================\n",
    "def train_single_lgbm(X_train, y_train, X_valid, y_valid, seed):\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        objective=\"regression_l1\",   # MAE ê¸°ë°˜\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric=\"mae\",\n",
    "    )\n",
    "\n",
    "    pred_valid = model.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid, pred_valid)\n",
    "    print(f\"[Seed {seed}] Valid MAE (log1p-space) = {mae:.5f}\")\n",
    "\n",
    "    return model, mae\n",
    "\n",
    "\n",
    "def train_lgbm_seed_ensemble(\n",
    "    train_df: pd.DataFrame,\n",
    "    seeds = (42, 2024, 777),\n",
    "):\n",
    "    # feature / target ë¶„ë¦¬\n",
    "    drop_cols = {\n",
    "        \"date\",\n",
    "        \"target_date\",\n",
    "        \"target_value\",\n",
    "        \"target_log1p\",\n",
    "        \"leading_item_id\",\n",
    "        \"following_item_id\",\n",
    "        \"a_raw\",        # ì›ì‹œ leader ê°’ì€ í”¼ì²˜ì—ì„œ ì œì™¸\n",
    "    }\n",
    "    feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "    # time-based split\n",
    "    train_cutoff = pd.Timestamp(\"2024-12-01\")\n",
    "    valid_start  = pd.Timestamp(\"2025-01-01\")\n",
    "    valid_end    = pd.Timestamp(\"2025-05-01\")\n",
    "\n",
    "    base_mask = train_df[\"target_log1p\"].notnull()\n",
    "\n",
    "    train_mask = (train_df[\"target_date\"] <= train_cutoff) & base_mask\n",
    "    valid_mask = (\n",
    "        (train_df[\"target_date\"] >= valid_start)\n",
    "        & (train_df[\"target_date\"] <= valid_end)\n",
    "        & base_mask\n",
    "    )\n",
    "\n",
    "    X_train = train_df.loc[train_mask, feature_cols]\n",
    "    y_train = train_df.loc[train_mask, \"target_log1p\"]\n",
    "\n",
    "    X_valid = train_df.loc[valid_mask, feature_cols]\n",
    "    y_valid = train_df.loc[valid_mask, \"target_log1p\"]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_valid) == 0:\n",
    "        raise ValueError(\"train/valid ë¶„í•  í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„ ì„¤ì • í™•ì¸ í•„ìš”)\")\n",
    "\n",
    "    print(f\"[Split] Train: {X_train.shape}, Valid: {X_valid.shape}\")\n",
    "\n",
    "    models, maes = [], []\n",
    "    for seed in seeds:\n",
    "        model, mae = train_single_lgbm(X_train, y_train, X_valid, y_valid, seed)\n",
    "        models.append(model)\n",
    "        maes.append(mae)\n",
    "\n",
    "    print(f\"[Ensemble] Avg MAE (log1p-space) = {np.mean(maes):.5f}\")\n",
    "    return models, feature_cols\n",
    "\n",
    "\n",
    "def predict_ensemble(models, X):\n",
    "    preds = [m.predict(X) for m in models]\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. inference: 2025-08 íƒ€ê¹ƒ row feature ìƒì„±\n",
    "# ============================================================\n",
    "def build_inference_features(\n",
    "    pivot: pd.DataFrame,\n",
    "    pairs_df: pd.DataFrame,\n",
    "    forecast_month: str = \"2025-08\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - forecast_month: 'YYYY-MM' ë¬¸ìì—´\n",
    "    - target_date == forecast_month-01 ì¸ rowë¥¼ ì°¾ê¸° ìœ„í•´,\n",
    "      base_date = target_date - 1 month ë¥¼ ê¸°ì¤€ìœ¼ë¡œ row í•˜ë‚˜ë¥¼ ë½‘ëŠ”ë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    target_ts = pd.Timestamp(forecast_month + \"-01\")\n",
    "    base_ts = target_ts - pd.offsets.MonthBegin(1)   # ì˜ˆ: 2025-08 â†’ 2025-07-01\n",
    "\n",
    "    rows = []\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        pair_frame = _build_pair_frame(\n",
    "            pivot=pivot,\n",
    "            leader=row[\"leading_item_id\"],\n",
    "            follower=row[\"following_item_id\"],\n",
    "            best_lag=int(row[\"best_lag\"]),\n",
    "            max_corr=float(row[\"max_corr\"]),\n",
    "        )\n",
    "\n",
    "        # history í™•ë³´\n",
    "        pair_frame = pair_frame.dropna(subset=[\"b_t_2\", \"a_t_aligned_2\"])\n",
    "\n",
    "        # base_ts ì— í•´ë‹¹í•˜ëŠ” row ì¶”ì¶œ\n",
    "        target_row = pair_frame[pair_frame[\"date\"] == base_ts]\n",
    "        if not target_row.empty:\n",
    "            rows.append(target_row.iloc[0])\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pred_df = pd.DataFrame(rows).reset_index(drop=True)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. ì œì¶œ ìƒì„± (value >= 1000ë§Œ ë‚¨ê¹€)\n",
    "# ============================================================\n",
    "def create_submission(\n",
    "    pairs_df: pd.DataFrame,\n",
    "    pred_df: pd.DataFrame,\n",
    "    models,\n",
    "    feature_cols,\n",
    "    min_value: int = 1000,\n",
    ") -> pd.DataFrame:\n",
    "    if pred_df.empty:\n",
    "        raise ValueError(\"pred_df ë¹„ì–´ ìˆìŒ. (inference feature ì—†ìŒ)\")\n",
    "\n",
    "    # feature ë§¤ì¹­ìš© merge\n",
    "    sub = pairs_df[[\"leading_item_id\", \"following_item_id\"]].copy()\n",
    "\n",
    "    sub = sub.merge(\n",
    "        pred_df[[\"leading_item_id\", \"following_item_id\"] + feature_cols],\n",
    "        on=[\"leading_item_id\", \"following_item_id\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    if len(sub) == 0:\n",
    "        raise ValueError(\"merge í›„ ì˜ˆì¸¡ ê°€ëŠ¥í•œ pairê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    X_test = sub[feature_cols].fillna(0.0)\n",
    "    y_pred_log = predict_ensemble(models, X_test)\n",
    "    y_pred = np.expm1(y_pred_log)  # ì—­ log1p\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "\n",
    "    sub[\"value\"] = y_pred.round().astype(int)\n",
    "\n",
    "    print(f\"[INFO] raw submission rows: {len(sub)}\")\n",
    "\n",
    "    # ğŸ”¥ value â‰¥ min_value ì¸ pairë§Œ ë‚¨ê¹€\n",
    "    sub = sub[sub[\"value\"] >= min_value].reset_index(drop=True)\n",
    "    print(f\"[INFO] filtered submission rows (value >= {min_value}): {len(sub)}\")\n",
    "\n",
    "    return sub[[\"leading_item_id\", \"following_item_id\", \"value\"]]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. MAIN\n",
    "# ============================================================\n",
    "def main():\n",
    "    print(\"=== [1] Load monthly & pivot ===\")\n",
    "    _, pivot = load_monthly_data()\n",
    "\n",
    "    print(\"=== [2] Load pairs_v10_best (BayesOpt í•„í„° ë°˜ì˜ë³¸) ===\")\n",
    "    pairs_df = pd.read_csv(PAIRS_PATH)\n",
    "    print(f\"[INFO] pairs_v10_best rows: {len(pairs_df)}\")\n",
    "\n",
    "    # ì¶”ê°€ EDA í•„í„°ë§ ì—†ìŒ (ì´ë¯¸ ì „ì²˜ë¦¬ì—ì„œ best í•„í„° ì ìš©)\n",
    "\n",
    "    print(\"=== [3] Build training df (hybrid FE) ===\")\n",
    "    train_df = build_training_data(pivot, pairs_df)\n",
    "    print(f\"[INFO] training rows: {len(train_df)}\")\n",
    "\n",
    "    print(\"=== [4] Train LGBM seed ensemble (MAE objective) ===\")\n",
    "    models, feature_cols = train_lgbm_seed_ensemble(train_df)\n",
    "\n",
    "    print(\"=== [5] Build inference features for 2025-08 ===\")\n",
    "    pred_df = build_inference_features(pivot, pairs_df, forecast_month=\"2025-08\")\n",
    "    print(f\"[INFO] pred_df rows: {len(pred_df)}\")\n",
    "\n",
    "    print(\"=== [6] Create submission (value >= 1000 only) ===\")\n",
    "    submission = create_submission(\n",
    "        pairs_df=pairs_df,\n",
    "        pred_df=pred_df,\n",
    "        models=models,\n",
    "        feature_cols=feature_cols,\n",
    "        min_value=1000,\n",
    "    )\n",
    "\n",
    "    out_path = OUTPUT_DIR / \"submission_v13_lgbm_hybrid_valge1000.csv\"\n",
    "    submission.to_csv(out_path, index=False)\n",
    "    print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c6b18-45b8-4e1c-96fc-ca48f2984af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
